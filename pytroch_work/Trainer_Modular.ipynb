{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### torchvision의 models 모듈로 pretrained 모델 생성","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndef create_resnet_model(model_name, num_classes=10, weights='DEFAULT'):\n    model = None\n    if model_name == 'resnet50':\n        model = models.resnet50(weights=weights)\n    elif model_name == 'resnext50_32x4d':\n        model = models.resnext50_32x4d(weights=weights)\n    \n    num_in_features = model.fc.in_features\n    model.fc = nn.Linear(in_features=num_in_features, out_features=num_classes)\n\n    return model\n    \nmodel = create_resnet_model('resnet50', num_classes=2, weights='DEFAULT') #resnet50, resnext50_32x4d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:13:17.213325Z","iopub.execute_input":"2025-01-31T04:13:17.213592Z","iopub.status.idle":"2025-01-31T04:13:24.400780Z","shell.execute_reply.started":"2025-01-31T04:13:17.213573Z","shell.execute_reply":"2025-01-31T04:13:24.400077Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:01<00:00, 78.0MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 개와 고양이 데이터 세트 다운로드 후 메타 데이터 생성","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\n\ndef create_cnd_meta_df(file_dir):\n    paths = [] # 이미지 파일 경로 리스트\n    dataset_gubuns = [] # 학습과 테스트\n    label_gubuns = [] # 개와 고양이\n    # os.walk()를 이용하여 특정 디렉토리 밑에 있는 모든 하위 디렉토리를 모두 조사. \n    # cat-and-dog 하위 디렉토리 밑에 jpg 확장자를 가진 파일이 모두 이미지 파일임\n    # cat-and-dog 밑으로 /train/, /test/ 하위 디렉토리 존재(학습, 테스트 용 이미지 파일들을 가짐)\n    for dirname, _, filenames in os.walk(file_dir):\n        for filename in filenames:\n            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n            if '.jpg' in filename:\n                # 파일의 절대 경로를 file_path 변수에 할당. \n                file_path = dirname+'/'+ filename\n                paths.append(file_path)\n                # 파일의 절대 경로에 training_set, test_set가 포함되어 있으면 데이터 세트 구분을 'train'과 'test'로 분류. \n                if '/training_set/' in file_path:\n                    dataset_gubuns.append('train')  \n                elif '/test_set/' in file_path:\n                    dataset_gubuns.append('test')\n                else: dataset_gubuns.append('N/A')\n                \n                # 파일의 절대 경로에 dogs가 있을 경우 해당 파일은 dog 이미지 파일이고, cats일 경우는 cat 이미지 파일임. \n                if 'dogs' in file_path:\n                    label_gubuns.append('DOG')\n                elif 'cats' in file_path:\n                    label_gubuns.append('CAT')\n                else: label_gubuns.append('N/A')\n    # DataFrame 메타 데이터 생성. \n    data_df = pd.DataFrame({'path':paths, \n                            'dataset':dataset_gubuns, \n                            'label':label_gubuns})\n    # Target값 0, 1 변환\n    label_mapping = {'DOG': 0, 'CAT': 1}\n    data_df['target'] = data_df['label'].map(label_mapping)\n\n    return data_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:13:24.401478Z","iopub.execute_input":"2025-01-31T04:13:24.401813Z","iopub.status.idle":"2025-01-31T04:13:25.269738Z","shell.execute_reply.started":"2025-01-31T04:13:24.401791Z","shell.execute_reply":"2025-01-31T04:13:25.268849Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### 학습, 검증, 테스트 데이터로 나누고 Dataset 및 DataLoader 생성\n* 학습 시간을 줄이기 위해서 학습과 검증 데이터를 줄임","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T00:57:36.210416Z","iopub.execute_input":"2025-01-31T00:57:36.210793Z","iopub.status.idle":"2025-01-31T00:57:36.354622Z","shell.execute_reply.started":"2025-01-31T00:57:36.210762Z","shell.execute_reply":"2025-01-31T00:57:36.353902Z"}},"outputs":[{"name":"stdout","text":"test_set  training_set\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"data_df = create_cnd_meta_df(file_dir='/kaggle/input/')\nprint(data_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:13:25.769766Z","iopub.execute_input":"2025-01-31T04:13:25.770211Z","iopub.status.idle":"2025-01-31T04:13:37.986755Z","shell.execute_reply.started":"2025-01-31T04:13:25.770184Z","shell.execute_reply":"2025-01-31T04:13:37.985842Z"}},"outputs":[{"name":"stdout","text":"(10028, 4)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 전체 데이터 세트에서 학습과 테스트용 메타 정보 DataFrame 생성. \ntrain_df = data_df[data_df['dataset']=='train']\ntest_df = data_df[data_df['dataset']=='test']\n\n# train_df의 50%를 train_df_temp로 할당. \ntrain_df_temp, _ = train_test_split(train_df, test_size=0.5, stratify=train_df['target'], random_state=2025)\n\n# 다시 train_df_temp의 50%씩 tr_df와 val_df로 할당.   \ntr_df, val_df = train_test_split(train_df_temp, test_size=0.5, stratify=train_df_temp['target'], random_state=2025)\n\nprint(data_df.shape, train_df.shape, tr_df.shape, val_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:13:37.987855Z","iopub.execute_input":"2025-01-31T04:13:37.988061Z","iopub.status.idle":"2025-01-31T04:13:38.010911Z","shell.execute_reply.started":"2025-01-31T04:13:37.988043Z","shell.execute_reply":"2025-01-31T04:13:38.010158Z"}},"outputs":[{"name":"stdout","text":"(10028, 4) (8005, 4) (2001, 4) (2001, 4)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"#### Dataset 및 학습/검증용 DataLoader 생성","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nfrom PIL import Image\n\nclass CnD_Dataset(Dataset):\n    # 이미지 파일리스트, 타겟 파일리스트, transforms 등 이미지와 타겟 데이터 가공에 필요한 인자들을 입력 받음\n    def __init__(self, image_paths, targets=None, transform=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n    \n    # 전체 건수를 반환\n    def __len__(self):\n        return len(self.image_paths)\n        \n    # idx로 지정된 하나의 image, label을 tensor 형태로 반환\n    def __getitem__(self, idx):    \n        # PIL을 이용하여 이미지 로딩하고 PIL Image 객체 반환.\n        pil_image = Image.open(self.image_paths[idx])\n        # 보통은 transform이 None이 되는 경우는 거의 없음(Tensor 변환이라도 있음)\n        image = self.transform(pil_image)\n\n        if self.targets is not None:\n            # 개별 target값을 tensor로 변환.\n            target = torch.tensor(self.targets[idx])\n            return image, target\n        # 테스트 데이터의 경우 targets가 입력 되지 않을 수 있으므로 이를 대비. \n        else:\n            return image, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:13:38.012357Z","iopub.execute_input":"2025-01-31T04:13:38.012675Z","iopub.status.idle":"2025-01-31T04:13:38.019691Z","shell.execute_reply.started":"2025-01-31T04:13:38.012637Z","shell.execute_reply":"2025-01-31T04:13:38.018973Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms as T\n\nBATCH_SIZE = 16\nIMG_SIZE = 224\nIMG_MEANS = [0.485, 0.456, 0.406] # ImageNet 데이터세트의 이미지 채널별 평균값\nIMG_STD = [0.229, 0.224, 0.225] # ImageNet 데이터세트의 이미지 채널별 표준편차값\n\ndef create_tr_val_loader(tr_df, val_df, transform):\n    tr_dataset = CnD_Dataset(image_paths=tr_df['path'].to_list(), \n                            targets=tr_df['target'].to_list(), transform=transform)\n    val_dataset = CnD_Dataset(image_paths=val_df['path'].to_list(), \n                            targets=val_df['target'].to_list(), transform=transform)\n    tr_loader = DataLoader(tr_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=2*BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\n    return tr_loader, val_loader\n\ntransform_01 = T.Compose([\n            T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n            T.ToTensor(), T.Normalize(mean=IMG_MEANS, std=IMG_STD)\n])\n\ntr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=transform_01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:13:38.020595Z","iopub.execute_input":"2025-01-31T04:13:38.020864Z","iopub.status.idle":"2025-01-31T04:13:38.039095Z","shell.execute_reply.started":"2025-01-31T04:13:38.020839Z","shell.execute_reply":"2025-01-31T04:13:38.038199Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Trainer 클래스 모듈화\n* 실습 github에서 utils.py를 다운로드 받고, 이를 kaggle 파일시스템에 저장한 뒤 해당 파일을 import하여 Trainer 클래스 로딩\n* Predictor, ModelCheckpoint, EarlyStopping 모두 utils.py에 클래스로 생성됨. ","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T00:57:39.291070Z","iopub.execute_input":"2025-01-31T00:57:39.291314Z","iopub.status.idle":"2025-01-31T00:57:39.435832Z","shell.execute_reply.started":"2025-01-31T00:57:39.291294Z","shell.execute_reply":"2025-01-31T00:57:39.435048Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# /kaggle/working/modular/v1 디렉토리에 utils.py 파일 다운로드\n!rm -rf ./modular/v1\n!mkdir -p ./modular/v1\n!wget -O ./modular/v1/utils.py https://raw.githubusercontent.com/chulminkw/CNN_PG_Torch/main/modular/v1/utils.py?raw=true\n!ls ./modular/v1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:42:39.237290Z","iopub.execute_input":"2025-01-31T04:42:39.237613Z","iopub.status.idle":"2025-01-31T04:42:39.940634Z","shell.execute_reply.started":"2025-01-31T04:42:39.237593Z","shell.execute_reply":"2025-01-31T04:42:39.939552Z"}},"outputs":[{"name":"stdout","text":"--2025-01-31 04:42:39--  https://raw.githubusercontent.com/chulminkw/CNN_PG_Torch/main/modular/v1/utils.py?raw=true\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 13594 (13K) [text/plain]\nSaving to: ‘./modular/v1/utils.py’\n\n./modular/v1/utils. 100%[===================>]  13.28K  --.-KB/s    in 0.001s  \n\n2025-01-31 04:42:39 (23.3 MB/s) - ‘./modular/v1/utils.py’ saved [13594/13594]\n\nutils.py\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!cat /kaggle/working/modular/v1/utils.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:42:41.186759Z","iopub.execute_input":"2025-01-31T04:42:41.187088Z","iopub.status.idle":"2025-01-31T04:42:41.332201Z","shell.execute_reply.started":"2025-01-31T04:42:41.187060Z","shell.execute_reply":"2025-01-31T04:42:41.331177Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport os\n\nclass Trainer:\n    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, \n                 callbacks=None, device=None):\n        self.model = model.to(device)\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        # scheduler 추가\n        self.scheduler = scheduler\n        self.device = device\n        # 현재 learning rate 변수 추가\n        self.current_lr = self.optimizer.param_groups[0]['lr']\n        #checkpoint와 early stopping 클래스들을 list로 받음. \n        self.callbacks = callbacks\n        \n    def train_epoch(self, epoch):\n        self.model.train()\n\n        # running 평균 loss 계산.\n        accu_loss = 0.0\n        running_avg_loss = 0.0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        # tqdm으로 실시간 training loop 진행 상황 시각화\n        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n                # 반드시 to(self.device). to(device) 아님.\n                inputs = inputs.to(self.device)\n                targets = targets.to(self.device)\n\n                # Forward pass\n                outputs = self.model(inputs)\n                loss = self.loss_fn(outputs, targets)\n\n                # Backward pass\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                accu_loss += loss.item()\n                running_avg_loss = accu_loss /(batch_idx + 1)\n\n                # accuracy metric 계산\n                # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                num_correct = (outputs.argmax(-1) == targets).sum().item()\n                # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n                num_total += inputs.shape[0]\n                accu_num_correct += num_correct\n                accuracy = accu_num_correct / num_total\n\n                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                progress_bar.update(1)\n                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                              \"Accuracy\": accuracy})\n\n        if (self.scheduler is not None) and (not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)):\n            self.scheduler.step()\n            self.current_lr = self.scheduler.get_last_lr()[0]\n        \n        return running_avg_loss, accuracy\n\n    def validate_epoch(self, epoch):\n        if not self.val_loader:\n            return None\n\n        self.model.eval()\n\n        # running 평균 loss 계산.\n        accu_loss = 0\n        running_avg_loss = 0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        current_lr = self.optimizer.param_groups[0]['lr']\n        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n\n                    outputs = self.model(inputs)\n\n                    loss = self.loss_fn(outputs, targets)\n                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                    accu_loss += loss.item()\n                    running_avg_loss = accu_loss /(batch_idx + 1)\n\n                    # accuracy metric 계산\n                    # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n                    # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n                    num_total += inputs.shape[0]\n                    accu_num_correct += num_correct\n                    accuracy = accu_num_correct / num_total\n                    \n                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                                  \"Accuracy\": accuracy})\n        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            self.scheduler.step(running_avg_loss)\n            self.current_lr = self.scheduler.get_last_lr()[0]\n\n        return running_avg_loss, accuracy\n\n    def fit(self, epochs):\n        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n        for epoch in range(epochs):\n            train_loss, train_acc = self.train_epoch(epoch)\n            val_loss, val_acc = self.validate_epoch(epoch)\n            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n                  f\", Current lr:{self.current_lr:.6f}\")\n            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n            history['lr'].append(self.current_lr)\n\n            # 만약 callbacks가 생성 인자로 들어온 다면 아래 수행. 만약 early stop 되어야 하면 is_epoch_loop_break로 for loop break\n            if self.callbacks:\n                is_epoch_loop_break = self._execute_callbacks(self.callbacks, self.model, epoch, val_loss, val_acc)\n                if is_epoch_loop_break:\n                    break\n                                \n        return history\n\n    # 생성 인자로 들어온 callbacks list을 하나씩 꺼내서 ModelCheckpoint, EarlyStopping을 수행. \n    # EarlyStopping 호출 시 early stop 여부를 판단하는 is_early_stopped 반환\n    def _execute_callbacks(self, callbacks, model, epoch, val_loss, val_acc):\n        is_early_stopped = False\n        \n        for callback in self.callbacks:\n            if isinstance(callback, ModelCheckpoint):\n                if callback.monitor == 'val_loss':    \n                    callback.save(model, epoch, val_loss)\n                elif callback.monitor == 'val_acc':\n                    callback.save(model, epoch, val_acc)\n            if isinstance(callback, EarlyStopping):\n                if callback.monitor == 'val_loss':\n                    is_early_stopped = callback.check_early_stop(val_loss)\n                if callback.monitor == 'val_acc':\n                    is_early_stopped = callback.check_early_stop(val_acc)\n                \n        return is_early_stopped\n\n    # 학습이 완료된 모델을 return\n    def get_trained_model(self):\n        return self.model\n    \nclass Predictor:\n    def __init__(self, model, device):\n        self.model = model.to(device)\n        self.device = device\n\n    def evaluate(self, loader):\n        # 현재 입력으로 들어온 데이터의 batch 통계(mean, variance)를 사용하지 않고, 학습 시 계산된 running 통계값을 사용\n        self.model.eval()\n        eval_metric = 0.0\n        # 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n\n        with tqdm(total=len(loader), desc=f\"[Evaluating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n                    pred = self.model(inputs)\n\n                    # 정확도 계산을 위해 누적 전체 건수와 누적 전체 num_correct 건수 계산  \n                    num_correct = (pred.argmax(-1) == targets).sum().item()\n                    num_total += inputs.shape[0]\n                    accu_num_correct += num_correct\n                    eval_metric = accu_num_correct / num_total\n\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n                        progress_bar.set_postfix({\"Accuracy\": eval_metric})\n        \n        return eval_metric\n\n    def predict_proba(self, inputs):\n        self.model.eval()\n        with torch.no_grad():\n            inputs = inputs.to(self.device)\n            outputs = self.model(inputs)\n            #예측값을 반환하므로 targets은 필요 없음.\n            #targets = targets.to(self.device)\n            pred_proba = F.softmax(outputs, dim=-1) #또는 dim=1\n\n        return pred_proba\n\n    def predict(self, inputs):\n        pred_proba = self.predict_proba(inputs)\n        pred_class = torch.argmax(pred_proba, dim=-1)\n\n        return pred_class\n\nclass EarlyStopping:\n    def __init__(self, monitor='val_loss', mode='min', early_patience=5, verbose=1):\n        self.monitor = monitor\n        self.mode = mode\n        self.early_patience = early_patience\n        self.verbose = verbose\n        self.best_value = float('inf') if mode == 'min' else -float('inf')\n        self.counter = 0\n\n    def is_improvement(self, value):\n        if self.mode == 'min':\n            return value < self.best_value\n        else:\n            return value > self.best_value\n\n    def check_early_stop(self, value):\n        is_early_stopped = False\n        \n        if self.is_improvement(value):\n            self.best_value = value\n            self.counter = 0\n            is_early_stopped =False\n        else:\n            self.counter += 1\n            if self.verbose:\n                print(f\"EarlyStopping counter: {self.counter}/{self.early_patience}\")\n            if self.counter >= self.early_patience:\n                is_early_stopped = True\n                if self.verbose:\n                    print(\"Early stopping happens and train stops\")\n        \n        return is_early_stopped\n    \n    import os\n\n\nclass ModelCheckpoint:\n    def __init__(self, checkpoint_dir='checkpoints', monitor='val_loss', mode='min', save_interval=1, verbose=1):\n        self.checkpoint_dir = checkpoint_dir\n        self.monitor = monitor\n        self.mode = mode\n        self.best_value = float('inf') if mode == 'min' else -float('inf')\n        self.verbose = verbose\n        self.save_interval = save_interval\n        self._make_checkpoint_dir_unless()\n\n    def _make_checkpoint_dir_unless(self):\n        if not os.path.exists(self.checkpoint_dir):\n            os.makedirs(self.checkpoint_dir)\n    \n    # mode 유형에 따라 metric value값이 이전 epoch시 보다 향상 되었는지 확인하여 True/False 값 return\n    def is_improvement(self, value):\n        if self.mode == 'min':\n            return value < self.best_value\n        else:\n            return value > self.best_value\n\n    # self.best_value값 update, is_improvement() 반환값이 True인 경우만 수행. \n    def update_best_value(self, value):\n        self.best_value = value\n\n    def save(self, model, epoch, value):\n        if self.save_interval == 1:\n            if self.is_improvement(value):\n                self._checkpoint_save(model, epoch, value)\n                self.update_best_value(value)\n            \n        elif self.save_interval > 1:\n            if (epoch + 1) % self.save_interval == 0:\n                self._checkpoint_save(model, epoch, value)\n                 \n        # 수행하지 말고 참조만 할 것(save_interval 횟수마다 model 성능이 향상되는 경우 저장)\n        # if (epoch + 1) % self.save_interval == 0 and self.is_improvement(value):\n        #     self.update_best_value(value)\n        #     self._checkpoint_save(model, epoch, value)\n            \n    def _checkpoint_save(self, model, epoch, value):\n        checkpoint_path = os.path.join(self.checkpoint_dir, \n                                       f'checkpoint_epoch_{epoch+1}_{self.monitor}_{value:.4f}.pt')\n        torch.save(model.state_dict(), checkpoint_path)\n        if self.verbose:\n            print(f\"Saved model checkpoint at {checkpoint_path}\")","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import sys\n\n# 반드시 system path를 아래와 같이 잡아줘야 함. \nsys.path.append('/kaggle/working')\n\n#아래가 수행되는지 반드시 확인\nfrom modular.v1.utils import Trainer, ModelCheckpoint, EarlyStopping\n\ncheckpoint_cb = ModelCheckpoint('checkpoints', monitor='val_loss', mode='min', save_interval=1, verbose=1)\nearlystop_cb = EarlyStopping(monitor='val_loss', mode='min', early_patience=2, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:42:46.915574Z","iopub.execute_input":"2025-01-31T04:42:46.915997Z","iopub.status.idle":"2025-01-31T04:42:46.921250Z","shell.execute_reply.started":"2025-01-31T04:42:46.915956Z","shell.execute_reply":"2025-01-31T04:42:46.920386Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Trainer 클래스를 utils.py에서 import하여 생성 및 모델 학습","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import SGD, Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n# 다운로드된 utils.py에서 class import\nfrom modular.v1.utils import Trainer, ModelCheckpoint, EarlyStopping\n\nmodel = create_resnet_model('resnet50', num_classes=2)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\noptimizer = Adam(model.parameters(), lr=0.001) # model.fc.parameters(), weight_decay=0.9\nloss_fn = nn.CrossEntropyLoss()\n# Patience를 3. \nscheduler = ReduceLROnPlateau(\n            optimizer=optimizer, mode='min', factor=0.5, patience=3, threshold=0.01, min_lr=0.00001)\n\ncheckpoint_cb = ModelCheckpoint('checkpoints', monitor='val_acc', mode='max', save_interval=1, verbose=1)\nearlystop_cb = EarlyStopping(monitor='val_acc', mode='max', early_patience=5, verbose=1)\ncallbacks = [checkpoint_cb, earlystop_cb]\ntrainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n                  train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, \n                  callbacks=callbacks,\n                  device=device)\n# 학습 및 평가. \nhistory = trainer.fit(30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T00:57:56.640663Z","iopub.execute_input":"2025-01-31T00:57:56.641008Z","iopub.status.idle":"2025-01-31T01:02:20.546030Z","shell.execute_reply.started":"2025-01-31T00:57:56.640984Z","shell.execute_reply":"2025-01-31T01:02:20.545064Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 [Training..]: 100%|██████████| 126/126 [00:13<00:00,  9.44it/s, Loss=0.267, Accuracy=0.901]\nEpoch 1 [Validating]: 100%|██████████| 63/63 [00:05<00:00, 11.35it/s, Loss=1.39, Accuracy=0.866] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30, Train Loss: 0.2673 Train Accuracy: 0.9005 , Val Loss: 1.3874 Val Accuracy: 0.8661 , Current lr:0.001000\nSaved model checkpoint at checkpoints/checkpoint_epoch_1_val_acc_0.8661.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.62it/s, Loss=0.276, Accuracy=0.884]\nEpoch 2 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.28it/s, Loss=0.228, Accuracy=0.913]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30, Train Loss: 0.2764 Train Accuracy: 0.8836 , Val Loss: 0.2277 Val Accuracy: 0.9130 , Current lr:0.001000\nSaved model checkpoint at checkpoints/checkpoint_epoch_2_val_acc_0.9130.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.58it/s, Loss=0.182, Accuracy=0.929]\nEpoch 3 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 13.27it/s, Loss=0.21, Accuracy=0.918] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30, Train Loss: 0.1824 Train Accuracy: 0.9290 , Val Loss: 0.2104 Val Accuracy: 0.9175 , Current lr:0.001000\nSaved model checkpoint at checkpoints/checkpoint_epoch_3_val_acc_0.9175.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Training..]: 100%|██████████| 126/126 [00:12<00:00, 10.47it/s, Loss=0.16, Accuracy=0.944] \nEpoch 4 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.94it/s, Loss=0.191, Accuracy=0.922]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30, Train Loss: 0.1600 Train Accuracy: 0.9435 , Val Loss: 0.1905 Val Accuracy: 0.9215 , Current lr:0.001000\nSaved model checkpoint at checkpoints/checkpoint_epoch_4_val_acc_0.9215.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.63it/s, Loss=0.147, Accuracy=0.951]\nEpoch 5 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.88it/s, Loss=0.683, Accuracy=0.811]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/30, Train Loss: 0.1471 Train Accuracy: 0.9510 , Val Loss: 0.6831 Val Accuracy: 0.8111 , Current lr:0.001000\nEarlyStopping counter: 1/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.62it/s, Loss=0.259, Accuracy=0.901]\nEpoch 6 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.96it/s, Loss=0.265, Accuracy=0.878]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/30, Train Loss: 0.2595 Train Accuracy: 0.9010 , Val Loss: 0.2651 Val Accuracy: 0.8781 , Current lr:0.001000\nEarlyStopping counter: 2/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.63it/s, Loss=0.173, Accuracy=0.936]\nEpoch 7 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.42it/s, Loss=0.228, Accuracy=0.917]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/30, Train Loss: 0.1733 Train Accuracy: 0.9355 , Val Loss: 0.2277 Val Accuracy: 0.9165 , Current lr:0.001000\nEarlyStopping counter: 3/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.64it/s, Loss=0.0725, Accuracy=0.978]\nEpoch 8 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.97it/s, Loss=0.266, Accuracy=0.918]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/30, Train Loss: 0.0725 Train Accuracy: 0.9775 , Val Loss: 0.2656 Val Accuracy: 0.9180 , Current lr:0.000500\nEarlyStopping counter: 4/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.63it/s, Loss=0.0477, Accuracy=0.984]\nEpoch 9 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.81it/s, Loss=0.159, Accuracy=0.944]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/30, Train Loss: 0.0477 Train Accuracy: 0.9840 , Val Loss: 0.1595 Val Accuracy: 0.9440 , Current lr:0.000500\nSaved model checkpoint at checkpoints/checkpoint_epoch_9_val_acc_0.9440.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.63it/s, Loss=0.0142, Accuracy=0.998]\nEpoch 10 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.45it/s, Loss=0.15, Accuracy=0.951] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/30, Train Loss: 0.0142 Train Accuracy: 0.9980 , Val Loss: 0.1502 Val Accuracy: 0.9505 , Current lr:0.000500\nSaved model checkpoint at checkpoints/checkpoint_epoch_10_val_acc_0.9505.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.64it/s, Loss=0.0203, Accuracy=0.995]\nEpoch 11 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.87it/s, Loss=0.121, Accuracy=0.955]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/30, Train Loss: 0.0203 Train Accuracy: 0.9945 , Val Loss: 0.1212 Val Accuracy: 0.9550 , Current lr:0.000500\nSaved model checkpoint at checkpoints/checkpoint_epoch_11_val_acc_0.9550.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.55it/s, Loss=0.00698, Accuracy=0.999]\nEpoch 12 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.72it/s, Loss=0.139, Accuracy=0.953]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/30, Train Loss: 0.0070 Train Accuracy: 0.9985 , Val Loss: 0.1388 Val Accuracy: 0.9525 , Current lr:0.000500\nEarlyStopping counter: 1/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.64it/s, Loss=0.00787, Accuracy=0.999]\nEpoch 13 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.76it/s, Loss=0.148, Accuracy=0.955]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/30, Train Loss: 0.0079 Train Accuracy: 0.9985 , Val Loss: 0.1480 Val Accuracy: 0.9545 , Current lr:0.000500\nEarlyStopping counter: 2/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.54it/s, Loss=0.0346, Accuracy=0.989]\nEpoch 14 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.76it/s, Loss=0.157, Accuracy=0.946]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/30, Train Loss: 0.0346 Train Accuracy: 0.9890 , Val Loss: 0.1567 Val Accuracy: 0.9460 , Current lr:0.000500\nEarlyStopping counter: 3/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.65it/s, Loss=0.0207, Accuracy=0.994]\nEpoch 15 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 13.71it/s, Loss=0.23, Accuracy=0.942] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/30, Train Loss: 0.0207 Train Accuracy: 0.9940 , Val Loss: 0.2303 Val Accuracy: 0.9420 , Current lr:0.000250\nEarlyStopping counter: 4/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.61it/s, Loss=0.00825, Accuracy=0.999]\nEpoch 16 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 15.04it/s, Loss=0.17, Accuracy=0.947] ","output_type":"stream"},{"name":"stdout","text":"Epoch 16/30, Train Loss: 0.0082 Train Accuracy: 0.9985 , Val Loss: 0.1696 Val Accuracy: 0.9465 , Current lr:0.000250\nEarlyStopping counter: 5/5\nEarly stopping happens and train stops\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"#### Predictor 클래스를 import 하여 테스트 데이터 평가 예측\n","metadata":{}},{"cell_type":"code","source":"from modular.v1.utils import Predictor\n\ntest_image_paths = test_df['path'].to_list()\ntest_targets = test_df['target'].to_list()\n\nIMG_SIZE=224\ntest_transform = T.Compose([\n                        T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n                        T.ToTensor(), \n                        T.Normalize(mean=[0.485, 0.456, 0.406], \n                                    std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = CnD_Dataset(image_paths=test_image_paths, \n                            targets=test_targets, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\ntrained_model = trainer.get_trained_model()\n\npredictor = Predictor(model=trained_model, device=device)\neval_metric = predictor.evaluate(test_loader)\nprint(f'test dataset evaluation:{eval_metric:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T01:02:20.547375Z","iopub.execute_input":"2025-01-31T01:02:20.547614Z","iopub.status.idle":"2025-01-31T01:02:26.397670Z","shell.execute_reply.started":"2025-01-31T01:02:20.547591Z","shell.execute_reply":"2025-01-31T01:02:26.396704Z"}},"outputs":[{"name":"stderr","text":"[Evaluating]: 100%|██████████| 64/64 [00:05<00:00, 10.97it/s, Accuracy=0.948]","output_type":"stream"},{"name":"stdout","text":"test dataset evaluation:0.9476\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### torchmetrics를 활용한 평가\n* 모델의 성능을 측정하기 위한 다양한 평가 지표가(정확도, F1 Score, ROC-AUC등) 있지만 pytorch framework은 이들 성능 지표를 위한 라이브러리를 제공하지 않음. \n* torchmetric(https://lightning.ai/docs/torchmetrics/stable/) 은 다양한 유형의 Metric을 라이브러리로 제공하므로 직접 Metric을 작성할 필요가 없음\n* 분류, 클러스터링 뿐만 아니라 Object Detection에 관련된 다양한 Metric을 제공.\n* metric객체의 주요 메소드\n    * update() 메소드는 train/valid/test loader의 loop내에서 호출되어 지표 계산에 필요한 메트릭 내부 변수의 값을 update함(counter나 현재까지 정확한 예측 건수등)\n    * compute() 메소드는 메트릭 값을 계산하여 반환.\n    * reset() 메소드는 지금까지 update된 메트릭 내부 변수의 값을 초기화","metadata":{}},{"cell_type":"code","source":"#이미 캐글 커널에 torchmetrics가 설치되어 있음. \n#!pip install torchmetrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchmetrics\nprint(torchmetrics.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:14:13.210844Z","iopub.execute_input":"2025-01-31T04:14:13.211161Z","iopub.status.idle":"2025-01-31T04:14:16.057606Z","shell.execute_reply.started":"2025-01-31T04:14:13.211137Z","shell.execute_reply":"2025-01-31T04:14:16.056654Z"}},"outputs":[{"name":"stdout","text":"1.6.1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"#### Accuracy Class 활용하기\n* 정확도는 torch.metric.classification.Accuracy로 제공. 이진 분류인 경우는 BinaryAccuracy, 다중 분류인 경우는 MulticlassAccuracy 클래스를 활용할 수도 있지만, 보통은 Accuracy 클래스의 생성 인자로 이들을 구분하여 적용함. MulticlassAccuracy 적용시에는 average의 default값이 micro가 아니라 macro이므로 이에 유의해야 함.\n* torchmetrics의 Metric 클래스(예를 들어 Accuracy)는 device를 입력 tensor의 device와 동일하게 설정해 줘야함 to(device)로 설정하며 입력 tensor의 device와 Metric 객체의 device가 다르면 오류 발생.\n* update() 메소드의 입력 인자로 사용되는 예측 Tensor는 argmax() 적용된 클래스값 또는 클래스 개수 레벨로 되어 있는 logit이나 class probability을 예측 Tensor로 입력하면 Accuracy Class가 argmax를 적용하여 계산함. ","metadata":{}},{"cell_type":"code","source":"from torch import tensor\nfrom torchmetrics.classification import Accuracy, MulticlassAccuracy\n\ntarget = tensor([2, 1, 0, 0])\npreds = tensor([2, 1, 0, 1])\n\n# Accuracy 클래스는 task에 multiclass로 MulticlassAccuray 설정. Accuracy의 average default값은 micro\nacc_metric = Accuracy(task=\"multiclass\", num_classes=3) #average='micro'\nacc_tensor = acc_metric(preds, target)\nprint('Accuracy 적용:', acc_tensor)\n\n# MulticlassAccuracy의 average default값은 macro\nm_acc_metric = MulticlassAccuracy(num_classes=3)\nprint('MulticlassAccuracy 적용:', m_acc_metric(preds, target).item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:22:34.902362Z","iopub.execute_input":"2025-01-31T04:22:34.902657Z","iopub.status.idle":"2025-01-31T04:22:34.912795Z","shell.execute_reply.started":"2025-01-31T04:22:34.902630Z","shell.execute_reply":"2025-01-31T04:22:34.911938Z"}},"outputs":[{"name":"stdout","text":"Accuracy 적용: tensor(0.7500)\nMulticlassAccuracy 적용: 0.8333333730697632\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntarget = tensor([2, 1, 0, 0]).to(device)\npreds = tensor([2, 1, 0, 1]).to(device)\n\naccuracy_metric = Accuracy(task=\"multiclass\", num_classes=3).to(device) # to(device)제거\naccuracy_metric.update(preds, target)\n\nprint(accuracy_metric.compute()) #accuracy_metric.compute().item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:27:00.933592Z","iopub.execute_input":"2025-01-31T04:27:00.933899Z","iopub.status.idle":"2025-01-31T04:27:00.942897Z","shell.execute_reply.started":"2025-01-31T04:27:00.933874Z","shell.execute_reply":"2025-01-31T04:27:00.942196Z"}},"outputs":[{"name":"stdout","text":"tensor(0.7500, device='cuda:0')\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### torchmetrics 를 적용한 TrainerWithTM 클래스 생성","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport os\n\nclass TrainerWithTM:\n    # metric 입력 변수 추가. \n    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, \n                 callbacks=None, metric=None, device=None):\n        self.model = model.to(device)\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        # scheduler 추가\n        self.scheduler = scheduler\n        self.device = device\n        # 현재 learning rate 변수 추가\n        self.current_lr = self.optimizer.param_groups[0]['lr']\n        #checkpoint와 early stopping 클래스들을 list로 받음. \n        self.callbacks = callbacks\n        #torchmetrics 객체 입력 받음\n        self.metric = metric.to(device)\n        \n    def train_epoch(self, epoch):\n        self.model.train()\n\n        # running 평균 loss 계산.\n        accu_loss = 0.0\n        running_avg_loss = 0.0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        # metric 초기화\n        self.metric.reset()\n        \n        # tqdm으로 실시간 training loop 진행 상황 시각화\n        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n                # 반드시 to(self.device). to(device) 아님.\n                inputs = inputs.to(self.device)\n                targets = targets.to(self.device)\n\n                # Forward pass\n                outputs = self.model(inputs)\n                loss = self.loss_fn(outputs, targets)\n\n                # Backward pass\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                accu_loss += loss.item()\n                running_avg_loss = accu_loss /(batch_idx + 1)\n\n                # # accuracy metric 계산\n                # # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                # num_correct = (outputs.argmax(-1) == targets).sum().item()\n                # # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n                # num_total += inputs.shape[0]\n                # accu_num_correct += num_correct\n                # accuracy = accu_num_correct / num_total\n\n                # torchmetric accuracy 계산. 예측된 output값을 넣거나, outputs.argmax(-1)로 예측 클래스값을 넣어도 됨.\n                self.metric.update(outputs, targets)\n                \n                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                progress_bar.update(1)\n                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                              # \"Accuracy\": accuracy,\n                                              \"Accuracy\": self.metric.compute().item() })\n\n        if (self.scheduler is not None) and (not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)):\n            self.scheduler.step()\n            self.current_lr = self.scheduler.get_last_lr()[0]\n        \n        return running_avg_loss, self.metric.compute().item()\n        # return running_avg_loss, accuracy, self.metric.compute().item()\n\n    def validate_epoch(self, epoch):\n        if not self.val_loader:\n            return None\n\n        self.model.eval()\n\n        # running 평균 loss 계산.\n        accu_loss = 0\n        running_avg_loss = 0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        current_lr = self.optimizer.param_groups[0]['lr']\n        # metric 초기화\n        self.metric.reset()\n        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n\n                    outputs = self.model(inputs)\n\n                    loss = self.loss_fn(outputs, targets)\n                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                    accu_loss += loss.item()\n                    running_avg_loss = accu_loss /(batch_idx + 1)\n\n                    # # accuracy metric 계산\n                    # # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                    # num_correct = (outputs.argmax(-1) == targets).sum().item()\n                    # # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n                    # num_total += inputs.shape[0]\n                    # accu_num_correct += num_correct\n                    # accuracy = accu_num_correct / num_total\n\n                    # torchmetric 계산 \n                    self.metric.update(outputs, targets)\n                    \n                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                                  # \"Accuracy\": accuracy,\n                                                  \"Accuracy\": self.metric.compute().item()})\n        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            self.scheduler.step(running_avg_loss)\n            self.current_lr = self.scheduler.get_last_lr()[0]\n\n        return running_avg_loss, self.metric.compute().item()\n        # return running_avg_loss, accuracy, self.metric.compute().item()\n\n    def fit(self, epochs):\n        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n        for epoch in range(epochs):\n            train_loss, train_acc = self.train_epoch(epoch)\n            val_loss, val_acc = self.validate_epoch(epoch)\n            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n                  f\", Current lr:{self.current_lr:.6f}\")\n            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n            history['lr'].append(self.current_lr)\n\n            # 만약 callbacks가 생성 인자로 들어온 다면 아래 수행. 만약 early stop 되어야 하면 is_epoch_loop_break로 for loop break\n            if self.callbacks:\n                is_epoch_loop_break = self._execute_callbacks(self.callbacks, self.model, epoch, val_loss, val_acc)\n                if is_epoch_loop_break:\n                    break\n                                \n        return history\n\n    # 생성 인자로 들어온 callbacks list을 하나씩 꺼내서 ModelCheckpoint, EarlyStopping을 수행. \n    # EarlyStopping 호출 시 early stop 여부를 판단하는 is_early_stopped 반환\n    def _execute_callbacks(self, callbacks, model, epoch, val_loss, val_acc):\n        is_early_stopped = False\n        \n        for callback in self.callbacks:\n            if isinstance(callback, ModelCheckpoint):\n                if callback.monitor == 'val_loss':    \n                    callback.save(model, epoch, val_loss)\n                elif callback.monitor == 'val_acc':\n                    callback.save(model, epoch, val_acc)\n            if isinstance(callback, EarlyStopping):\n                if callback.monitor == 'val_loss':\n                    is_early_stopped = callback.check_early_stop(val_loss)\n                if callback.monitor == 'val_acc':\n                    is_early_stopped = callback.check_early_stop(val_acc)\n                \n        return is_early_stopped\n\n    # 학습이 완료된 모델을 return\n    def get_trained_model(self):\n        return self.model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:40:32.286785Z","iopub.execute_input":"2025-01-31T04:40:32.287124Z","iopub.status.idle":"2025-01-31T04:40:32.304423Z","shell.execute_reply.started":"2025-01-31T04:40:32.287097Z","shell.execute_reply":"2025-01-31T04:40:32.303615Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import SGD, Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchmetrics.classification import Accuracy\n\nmodel = create_resnet_model('resnet50', num_classes=2)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\noptimizer = Adam(model.parameters(), lr=0.001) # model.fc.parameters(), weight_decay=0.9\nloss_fn = nn.CrossEntropyLoss()\n# torchmetrics의 Accuracy 생성. \naccuracy_metric = Accuracy(task='multiclass', num_classes=2)\n# Patience를 3. \nscheduler = ReduceLROnPlateau(\n            optimizer=optimizer, mode='min', factor=0.5, patience=3, threshold=0.01, min_lr=0.00001)\n\ncheckpoint_cb = ModelCheckpoint('checkpoints', monitor='val_acc', mode='max', save_interval=1, verbose=1)\nearlystop_cb = EarlyStopping(monitor='val_acc', mode='max', early_patience=5, verbose=1)\ncallbacks = [checkpoint_cb, earlystop_cb]\n\ntrainer = TrainerWithTM(model=model, loss_fn=loss_fn, optimizer=optimizer,\n                  train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, \n                  callbacks=callbacks, metric=accuracy_metric,\n                  device=device)\n# 학습 및 평가. \nhistory = trainer.fit(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:42:58.573649Z","iopub.execute_input":"2025-01-31T04:42:58.573945Z","iopub.status.idle":"2025-01-31T04:44:08.638464Z","shell.execute_reply.started":"2025-01-31T04:42:58.573924Z","shell.execute_reply":"2025-01-31T04:44:08.637210Z"}},"outputs":[{"name":"stderr","text":"Epoch 1 [Training..]: 100%|██████████| 126/126 [00:13<00:00,  9.52it/s, Loss=0.373, Accuracy_01=0.856, Accuracy_02=0.856]\nEpoch 1 [Validating]: 100%|██████████| 63/63 [00:05<00:00, 10.62it/s, Loss=0.386, Accuracy_01=0.826, Accuracy_02=0.826]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Train Loss: 0.3727 Train Accuracy: 0.8556 , Val Loss: 0.3862 Val Accuracy: 0.8261 , Current lr:0.001000\nSaved model checkpoint at checkpoints/checkpoint_epoch_1_val_acc_0.8261.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.53it/s, Loss=0.234, Accuracy_01=0.908, Accuracy_02=0.908]\nEpoch 2 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 13.97it/s, Loss=0.224, Accuracy_01=0.907, Accuracy_02=0.907]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Train Loss: 0.2341 Train Accuracy: 0.9075 , Val Loss: 0.2236 Val Accuracy: 0.9070 , Current lr:0.001000\nSaved model checkpoint at checkpoints/checkpoint_epoch_2_val_acc_0.9070.pt\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.56it/s, Loss=0.247, Accuracy_01=0.905, Accuracy_02=0.905]\nEpoch 3 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.15it/s, Loss=0.363, Accuracy_01=0.879, Accuracy_02=0.879]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Train Loss: 0.2471 Train Accuracy: 0.9050 , Val Loss: 0.3634 Val Accuracy: 0.8791 , Current lr:0.001000\nEarlyStopping counter: 1/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Training..]: 100%|██████████| 126/126 [00:11<00:00, 10.54it/s, Loss=0.164, Accuracy_01=0.943, Accuracy_02=0.943]\nEpoch 4 [Validating]: 100%|██████████| 63/63 [00:04<00:00, 14.28it/s, Loss=0.288, Accuracy_01=0.875, Accuracy_02=0.875]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Train Loss: 0.1640 Train Accuracy: 0.9425 , Val Loss: 0.2879 Val Accuracy: 0.8751 , Current lr:0.001000\nEarlyStopping counter: 2/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Training..]:   4%|▍         | 5/126 [00:00<00:19,  6.22it/s, Loss=0.206, Accuracy_01=0.875, Accuracy_02=0.875]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-88105cf58cf0>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                   device=device)\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 학습 및 평가.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-64f3139f04d6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n","\u001b[0;32m<ipython-input-20-64f3139f04d6>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0maccu_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mrunning_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccu_loss\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}