{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9519275,"sourceType":"datasetVersion","datasetId":5795628}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### CutMix 적용","metadata":{}},{"cell_type":"markdown","source":"#### Flowers 데이터 세트 다운로드 및 메타 데이터 생성\n* 총 3670장의 이미지로 구성되어 있으며 꽃 유형(daisy, dandelion, rose, sunflower, tulip)을 판별하기 위한 이미지 데이터 세트\n* 개별 디렉토리 명이 꽃이름으로 되어 있음\n* 전체의 70%를 학습, 30%를 테스트로 분할뒤, 다시 학습 데이터의 80%를 학습, 20%를 검증으로 분할","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\ndef create_flowers_meta_df(file_dir):\n    paths = [] # 이미지 파일 경로 리스트\n    \n    labels = [] # 꽃 종류\n    \n    # os.walk()를 이용하여 특정 디렉토리 밑에 있는 모든 하위 디렉토리를 모두 조사. \n    # kaggle/input/flowers-dataset 하위 디렉토리 밑에 jpg 확장자를 가진 파일이 모두 이미지 파일임\n    # kaggle/input/flowers-dataset 밑으로 하위 디렉토리 존재\n    for dirname, _, filenames in os.walk(file_dir):\n        for filename in filenames:\n            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n            if '.jpg' in filename:\n                # 파일의 절대 경로를 file_path 변수에 할당. \n                file_path = dirname+'/'+ filename\n                paths.append(file_path)\n                \n                # 파일의 절대 경로에 daily, dandelion, roses, sunflowers, tulips에 따라 labels에 값 할당.               label_gubuns.append('daisy')\n                if 'daisy' in file_path:\n                    labels.append('daisy')\n                elif 'dandelion' in file_path:\n                    labels.append('dandelion')\n                elif 'roses' in file_path:\n                    labels.append('rose')\n                elif 'sunflowers' in file_path:\n                    labels.append('sunflowers')\n                elif 'tulips' in file_path:\n                    labels.append('tulips')\n    # DataFrame 메타 데이터 생성. \n    data_df = pd.DataFrame({'path':paths, \n                            'label':labels})\n    # Target값  변환\n    label_mapping = {'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflowers': 3, 'tulips': 4}\n    data_df['target'] = data_df['label'].map(label_mapping)\n\n    return data_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata_df = create_flowers_meta_df('/kaggle/input/') # /kaggle/input/flowers-dataset\n\n# 전체 데이터 세트에서 학습(전체의 70%)과 테스트용(전체의 30%) 메타 정보 DataFrame 생성.\ntrain_df, test_df = train_test_split(data_df, test_size=0.3, stratify=data_df['target'], random_state=2025)\n# 기존 학습 DataFrame을 다시 학습과 검증 DataFrame으로 분할. 80%가 학습, 20%가 검증\ntr_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['target'], random_state=2025)\n\nprint(data_df.shape, train_df.shape, tr_df.shape, val_df.shape, test_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Flower Custom Dataset 및 DataLoader 생성","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nfrom PIL import Image\n\nclass FlowerDataset(Dataset):\n    # 이미지 파일리스트, 타겟 파일리스트, transforms 등 이미지와 타겟 데이터 가공에 필요한 인자들을 입력 받음\n    def __init__(self, image_paths, targets=None, transform=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n    \n    # 전체 건수를 반환\n    def __len__(self):\n        return len(self.image_paths)\n        \n    # idx로 지정된 하나의 image, label을 tensor 형태로 반환\n    def __getitem__(self, idx):    \n        # PIL을 이용하여 이미지 로딩하고 PIL Image 객체 반환.\n        pil_image = Image.open(self.image_paths[idx])\n        # 보통은 transform이 None이 되는 경우는 거의 없음(Tensor 변환이라도 있음)\n        image = self.transform(pil_image)\n\n        if self.targets is not None:\n            # 개별 target값을 tensor로 변환.\n            target = torch.tensor(self.targets[idx])\n            return image, target\n        # 테스트 데이터의 경우 targets가 입력 되지 않을 수 있으므로 이를 대비. \n        else:\n            return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms as T\n\nBATCH_SIZE = 32\n\ndef create_tr_val_loader(tr_df, val_df, transform):\n    tr_dataset = FlowerDataset(image_paths=tr_df['path'].to_list(), \n                            targets=tr_df['target'].to_list(), transform=transform)\n    val_dataset = FlowerDataset(image_paths=val_df['path'].to_list(), \n                            targets=val_df['target'].to_list(), transform=transform)\n    \n    tr_loader = DataLoader(tr_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=2*BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\n    return tr_loader, val_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = 224\nIMG_MEANS = [0.485, 0.456, 0.406] # ImageNet 데이터세트의 이미지 채널별 평균값\nIMG_STD = [0.229, 0.224, 0.225] # ImageNet 데이터세트의 이미지 채널별 표준편차값\n\ntrain_transform = T.Compose([\n            T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n            T.ToTensor(), T.Normalize(mean=IMG_MEANS, std=IMG_STD)\n])\n\ntr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=train_transform)\nimages, labels = next(iter(tr_loader))\nprint(images.shape, labels.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CutMix 시각화 해보기\n* uniform 분포로 0 ~ 1 사이값을 추출하고 이를 기반으로 cut할 이미지 영역 계산.\n* 원본 이미지에 cut 이미지 영역을 붙여 넣음. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision import transforms\n\ndef rand_bbox(size, lam):\n    \"\"\"잘라낼 영역을 bound box 형식으로 생성.\"\"\"\n    # 단일 이미지 입력 및 channel First 입력 시\n    W = size[1]\n    H = size[2]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.array(W * cut_rat).astype(np.int32)\n    cut_h = np.array(H * cut_rat).astype(np.int32)\n\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix_images(img1, img2, alpha=1.0):\n    \"\"\"img2에 있는 일정 영역을 잘라서 img1로 붙임.\"\"\"\n    lam = np.random.beta(alpha, alpha) # uniform 분포로 0 ~ 1 사이값 추출 \n    bbx1, bby1, bbx2, bby2 = rand_bbox(img1.size(), lam)\n    \n    img1[:, bbx1:bbx2, bby1:bby2] = img2[:, bbx1:bbx2, bby1:bby2]\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img1.size(1) * img1.size(2)))\n    print('cut w x h:', (bbx2-bbx1), (bby2-bby1), 'image w x h:', img1.size(1), img1.size(2))\n    \n    return img1, lam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"alpha = 1.0\nnp.random.beta(alpha, alpha)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Set the maximum column width to None (display all content)\npd.set_option('display.max_colwidth', None)\n\nprint(data_df[data_df['label'] == 'daisy']['path'].iloc[:2])\nprint(data_df[data_df['label'] == 'rose']['path'].iloc[:2])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms as T\n\ntransform = T.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\ndaisy_img = Image.open('/kaggle/input/flower_photos/daisy/8882282142_9be2524d38_m.jpg')\nrose_img = Image.open('/kaggle/input/flower_photos/roses/6108118824_5b0231a56d.jpg')\n\ndaisy_img_t = transform(daisy_img)\nrose_img_t = transform(rose_img)\n\ncutmix_img, lam = cutmix_images(daisy_img_t, rose_img_t)\nprint(type(cutmix_img), cutmix_img.shape, 'lam:', lam)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# channel last로 바꾸고 numpy로 변환. \ncutmix_img_np = cutmix_img.permute(1, 2, 0).numpy()\n\nplt.figure(figsize=(10, 5))\nplt.imshow(cutmix_img_np)\nplt.axis('off')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CutMix를 Batch단위로 이미지와 Target 값 함께 적용하기","metadata":{}},{"cell_type":"code","source":"torch.randperm(32)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\n\ndef rand_bbox(size, lam):\n    # batch 포함 4차원. Channel First의 size가 입력됨. \n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.array(W * cut_rat).astype(np.int32)\n    cut_h = np.array(H * cut_rat).astype(np.int32)\n\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    # 최소 0, 최대 W나 H 이상이 되지 않도록 clip적용. \n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix(images, targets, alpha=1.0, verbose=False):\n    \"\"\"\n    Args:\n        images (Tensor): 배치단위 images.\n        target (Tensor): 배치단위 labels.\n        alpha (float): 베타분포 alpah값.\n        \n    Returns:\n        Tuple[Tensor, Tensor, float]: CutMix 적용된 images, updated target, and lambda.\n    \"\"\"\n    # batch 크기에 따른 index값들을 random하게 shuffling\n    indices = torch.randperm(images.size(0))\n    shuffled_images = images[indices]\n    shuffled_targets = targets[indices]\n    \n    lam = np.random.beta(alpha, alpha)\n    # cut할 bbox 영역 추출. 배치레벨로 동일한 bbox 영역 추출\n    bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n    images[:, :, bbx1:bbx2, bby1:bby2] = shuffled_images[:, :, bbx1:bbx2, bby1:bby2]\n    # lam 값을 실제 image 대비 cut된 영역을 pixel 비율로 다시 계산. \n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n    if verbose:\n        print('cut w x h:', (bbx2-bbx1), (bby2-bby1), (bbx2 - bbx1) * (bby2 - bby1), \n              'image w x h:', images.size()[-1], images.size()[-2], (images.size()[-1] * images.size()[-2]))\n\n    return images, targets, shuffled_targets, lam","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = 224\nIMG_MEANS = [0.485, 0.456, 0.406] # ImageNet 데이터세트의 이미지 채널별 평균값\nIMG_STD = [0.229, 0.224, 0.225] # ImageNet 데이터세트의 이미지 채널별 표준편차값\n\ntrain_transform = T.Compose([\n            T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n            T.ToTensor(), # 시각화를 위해 Normalize()는 제외\n])\n\ntr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=train_transform)\n\nimages, targets = next(iter(tr_loader))\n\ncutmix_images, targets, shuffled_targets, lam = cutmix(images.clone(), targets.clone(), alpha=1.0, verbose=True)\nprint('targets:', targets, 'shuffled_targets:', shuffled_targets, 'lam:', lam )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_np = images.permute(0, 2, 3, 1).numpy()\ncutmix_images_np = cutmix_images.permute(0, 2, 3, 1).numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflowers': 3, 'tulips': 4\ndef show_grid_images_np(images_np, targets_np, ncols=6):\n    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n    for i in range(ncols):\n        axs[i].imshow(images_np[i])\n        axs[i].set_title(targets_np[i])\n        \nshow_grid_images_np(images_np, targets.numpy(), ncols=6)\nshow_grid_images_np(cutmix_images_np, shuffled_targets.numpy(), ncols=6)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CutMix 적용하여 학습 및 평가 수행\n* torchvision pretrained resnet 50 모델 생성\n* Train loop에 cut된 이미지 영역 비율을 반영하여 loss함수 재 구성","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndef create_resnet_model(model_name, num_classes=10, weights='DEFAULT'):\n    model = None\n    if model_name == 'resnet50':\n        model = models.resnet50(weights=weights)\n    elif model_name == 'resnet101':\n        model = models.resnet101(weights=weights)\n    \n    num_in_features = model.fc.in_features\n    model.fc = nn.Linear(in_features=num_in_features, out_features=num_classes)\n\n    return model\n    \nresnet_model = create_resnet_model('resnet50', num_classes=5, weights='DEFAULT') #resnet50, resnet101","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Trainer 클래스 생성 및 적용\n* Trainer loop에 cutmix일 경우 loss를 cut한 이미지 영역을 감안하여 적용하는 loss 재 구성\n* 생성 인자로 cutmix_proba 추가. 1일 경우 무조건 cutmix 수행. ","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn.functional as F\n\nclass Trainer:\n    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, \n                 callbacks=None, cutmix_proba=0, device=None):\n        self.model = model.to(device)\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        # scheduler 추가\n        self.scheduler = scheduler\n        self.device = device\n        # 현재 learning rate 변수 추가\n        self.current_lr = self.optimizer.param_groups[0]['lr']\n        #checkpoint와 early stopping 클래스들을 list로 받음. \n        self.callbacks = callbacks\n        #cutmix_prob 확률 설정\n        self.cutmix_proba = cutmix_proba\n        \n    def train_epoch(self, epoch):\n        self.model.train()\n\n        # running 평균 loss 계산.\n        accu_loss = 0.0\n        running_avg_loss = 0.0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        # tqdm으로 실시간 training loop 진행 상황 시각화\n        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n                # 반드시 to(self.device). to(device) 아님.\n                inputs = inputs.to(self.device)\n                targets = targets.to(self.device)\n                \n                # cutmix일 경우 forward pass 및 loss계산. \n                r = np.random.rand(1)\n                if r < self.cutmix_proba: \n                    inputs, targets_a, targets_b, lam = cutmix(inputs, targets.clone(), alpha=1.0)\n                    outputs = self.model(inputs)\n                    loss = lam * self.loss_fn(outputs, targets_a) + (1 - lam) * self.loss_fn(outputs, targets_b)\n                # cutmix가 아닐 경우 forward pass 및 loss 계산. \n                else:\n                    outputs = self.model(inputs)\n                    loss = self.loss_fn(outputs,targets)\n                    \n                # Backward pass\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                accu_loss += loss.item()\n                running_avg_loss = accu_loss /(batch_idx + 1)\n\n                # accuracy metric 계산\n                # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                num_correct = (outputs.argmax(-1) == targets).sum().item()\n                # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n                num_total += inputs.shape[0]\n                accu_num_correct += num_correct\n                accuracy = accu_num_correct / num_total\n\n                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                progress_bar.update(1)\n                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                              \"Accuracy\": accuracy})\n\n        if (self.scheduler is not None) and (not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau)):\n            self.scheduler.step()\n            self.current_lr = self.scheduler.get_last_lr()[0]\n        \n        return running_avg_loss, accuracy\n\n    def validate_epoch(self, epoch):\n        if not self.val_loader:\n            return None\n\n        self.model.eval()\n\n        # running 평균 loss 계산.\n        accu_loss = 0\n        running_avg_loss = 0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        current_lr = self.optimizer.param_groups[0]['lr']\n        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n\n                    outputs = self.model(inputs)\n\n                    loss = self.loss_fn(outputs, targets)\n                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                    accu_loss += loss.item()\n                    running_avg_loss = accu_loss /(batch_idx + 1)\n\n                    # accuracy metric 계산\n                    # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n                    # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산  \n                    num_total += inputs.shape[0]\n                    accu_num_correct += num_correct\n                    accuracy = accu_num_correct / num_total\n                    \n                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                                  \"Accuracy\": accuracy})\n        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            self.scheduler.step(running_avg_loss)\n            self.current_lr = self.scheduler.get_last_lr()[0]\n\n        return running_avg_loss, accuracy\n\n    def fit(self, epochs):\n        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n        for epoch in range(epochs):\n            train_loss, train_acc = self.train_epoch(epoch)\n            val_loss, val_acc = self.validate_epoch(epoch)\n            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n                  f\", Current lr:{self.current_lr:.6f}\")\n            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n            history['lr'].append(self.current_lr)\n\n            # 만약 callbacks가 생성 인자로 들어온 다면 아래 수행. 만약 early stop 되어야 하면 is_epoch_loop_break로 for loop break\n            if self.callbacks:\n                is_epoch_loop_break = self._execute_callbacks(self.callbacks, self.model, epoch, val_loss, val_acc)\n                if is_epoch_loop_break:\n                    break\n                                \n        return history\n\n    # 생성 인자로 들어온 callbacks list을 하나씩 꺼내서 ModelCheckpoint, EarlyStopping을 수행. \n    # EarlyStopping 호출 시 early stop 여부를 판단하는 is_early_stopped 반환\n    def _execute_callbacks(self, callbacks, model, epoch, val_loss, val_acc):\n        is_early_stopped = False\n        \n        for callback in self.callbacks:\n            if isinstance(callback, ModelCheckpoint):\n                if callback.monitor == 'val_loss':    \n                    callback.save(model, epoch, val_loss)\n                elif callback.monitor == 'val_acc':\n                    callback.save(model, epoch, val_acc)\n            if isinstance(callback, EarlyStopping):\n                if callback.monitor == 'val_loss':\n                    is_early_stopped = callback.check_early_stop(val_loss)\n                if callback.monitor == 'val_acc':\n                    is_early_stopped = callback.check_early_stop(val_acc)\n                \n        return is_early_stopped\n\n    # 학습이 완료된 모델을 return\n    def get_trained_model(self):\n        return self.model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import SGD, Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nNUM_INPUT_CHANNELS = 3\n# 5개의 꽃 종류\nNUM_CLASSES = 5\n\ndef train_flowers_with_aug(tr_df, val_df, transform, cutmix_proba=0, epochs=20):\n    tr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=transform)\n    model = create_resnet_model('resnet50', num_classes=NUM_CLASSES, weights='DEFAULT')\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    optimizer = Adam(model.parameters(), lr=0.001)\n    loss_fn = nn.CrossEntropyLoss()\n    scheduler = ReduceLROnPlateau(\n                optimizer=optimizer, mode='min', factor=0.5, patience=4, threshold=0.01, min_lr=0.00001)\n    # callbacks는 None\n    trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n                      train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, callbacks=None, \n                      cutmix_proba=cutmix_proba, device=device)\n    # 학습 및 평가.\n    history = trainer.fit(epochs)\n    #학습된 trainer와 history 반환. \n    return trainer, history\n\nIMG_SIZE = 224\ntrain_transform = T.Compose([\n                        T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n                        T.ToTensor(), \n                        T.Normalize(mean=[0.485, 0.456, 0.406], \n                                    std=[0.229, 0.224, 0.225])\n])\n\ntrainer, history = train_flowers_with_aug(tr_df, val_df, transform=train_transform,\n                                          cutmix_proba=1, epochs=30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Predictor:\n    def __init__(self, model, device):\n        self.model = model.to(device)\n        self.device = device\n\n    def evaluate(self, loader):\n        # 현재 입력으로 들어온 데이터의 batch 통계(mean, variance)를 사용하지 않고, 학습 시 계산된 running 통계값을 사용\n        self.model.eval()\n        eval_metric = 0.0\n        # 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n\n        with tqdm(total=len(loader), desc=f\"[Evaluating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n                    pred = self.model(inputs)\n\n                    # 정확도 계산을 위해 누적 전체 건수와 누적 전체 num_correct 건수 계산  \n                    num_correct = (pred.argmax(-1) == targets).sum().item()\n                    num_total += inputs.shape[0]\n                    accu_num_correct += num_correct\n                    eval_metric = accu_num_correct / num_total\n\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n                        progress_bar.set_postfix({\"Accuracy\": eval_metric})\n        \n        return eval_metric\n\n    def predict_proba(self, inputs):\n        self.model.eval()\n        with torch.no_grad():\n            inputs = inputs.to(self.device)\n            outputs = self.model(inputs)\n            #예측값을 반환하므로 targets은 필요 없음.\n            #targets = targets.to(self.device)\n            pred_proba = F.softmax(outputs, dim=-1) #또는 dim=1\n\n        return pred_proba\n\n    def predict(self, inputs):\n        pred_proba = self.predict_proba(inputs)\n        pred_class = torch.argmax(pred_proba, dim=-1)\n\n        return pred_class","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_image_paths = test_df['path'].to_list()\ntest_targets = test_df['target'].to_list()\n\nIMG_SIZE=224\ntest_transform = T.Compose([\n                        T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n                        T.ToTensor(), \n                        T.Normalize(mean=[0.485, 0.456, 0.406], \n                                    std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = FlowerDataset(image_paths=test_image_paths, \n                            targets=test_targets, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\ntrained_model = trainer.get_trained_model()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npredictor = Predictor(model=trained_model, device=device)\neval_metric = predictor.evaluate(test_loader)\nprint(f'test dataset evaluation:{eval_metric:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### CuxMix 확률을 0.5로 적용하여 수행. ","metadata":{}},{"cell_type":"code","source":"trainer, history = train_flowers_with_aug(tr_df, val_df, transform=train_transform,\n                                          cutmix_proba=0.5, epochs=30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trained_model = trainer.get_trained_model()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npredictor = Predictor(model=trained_model, device=device)\neval_metric = predictor.evaluate(test_loader)\nprint(f'test dataset evaluation:{eval_metric:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}