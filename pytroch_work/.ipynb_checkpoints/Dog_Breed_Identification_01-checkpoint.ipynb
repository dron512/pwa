{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Dog Breed 데이터 세트를 아래 URL에서 직접 Download 및 압축 해제\n",
    "* Kaggle의 Dataset으로 Object Storage 연결 시 이미지를 한장 씩 읽는 데 많은 시간이 소요되어 모델 학습에 시간이 더 걸림. \n",
    "* Local Disk에 바로 이미지를 다운로드/압축 해제 후 모델에서 이를 이용할 수 있도록 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n",
      "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "# stanford dog breed 데이터 세트 다운로드 \n",
    "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
    "# 현재 디렉토리인 /kaggle/working에 바로 압축 해제 \n",
    "!ls; tar -xvf images.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
      "��ġ ������ �ƴմϴ�.\n"
     ]
    }
   ],
   "source": [
    "# 현재 디렉토리의 내용 확인. \n",
    "!ls; pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "������ ��θ� ã�� �� �����ϴ�.\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/Images;ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/working/Images'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 파일들의 디렉토리와 파일명을 기반으로 메타 정보인 이미지 절대경로, 레이블을 DataFrame으로 생성\n",
    "* /kaggle/working/Images 디렉토리 밑에 Dog breed 서브 디렉토리와 이미지 파일로 구성 되어 있음. \n",
    "* 레이블 값은 이미지 파일의 절대경로에서 이미지 파일 바로 위에 있는 서브 디렉토리를 가공하여 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "IMAGE_DIR = '/kaggle/working/Images' \n",
    "\n",
    "def make_dogbreed_dataframe(image_dir=IMAGE_DIR):\n",
    "    paths = []\n",
    "    label_gubuns = []\n",
    "    for dirname, _, filenames in os.walk(image_dir):\n",
    "        for filename in filenames:\n",
    "            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n",
    "            if '.jpg' in filename:\n",
    "                # 파일의 절대 경로를 file_path 변수에 할당. \n",
    "                file_path = dirname+'/'+ filename\n",
    "                paths.append(file_path)\n",
    "                # 이미지 파일의 절대 경로에서 레이블명 생성을 위한 1차 추출. '/'로 분할하여 파일 바로 위 서브디렉토리 이름 가져옴.  \n",
    "                start_pos = file_path.find('/', 20)\n",
    "                end_pos = file_path.rfind('/')\n",
    "                imsi_breed = file_path[start_pos+1:end_pos]\n",
    "                # 1차 추출된 데이터를 기반으로 '-' 이후 데이터가 레이블 값임. \n",
    "                breed = imsi_breed[imsi_breed.find('-')+1:]\n",
    "                #print(start_pos, end_pos, imsi_breed, breed)\n",
    "                label_gubuns.append(breed)\n",
    "\n",
    "    data_df = pd.DataFrame({'path':paths, 'label':label_gubuns})\n",
    "    \n",
    "    #label에 따른 숫자 target 값 매핑\n",
    "    sorted_label = np.sort(data_df['label'].unique())\n",
    "    label_mapping = {label: index for index, label in enumerate(sorted_label)}\n",
    "    data_df['target'] = data_df['label'].map(label_mapping)\n",
    "    data_df = data_df.sort_values(by=['target', 'path'], ascending=True)\n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_df shape: (0, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [path, label, target]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "data_df = make_dogbreed_dataframe()\n",
    "print('data_df shape:', data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "sorted_label = np.sort(data_df['label'].unique())\n",
    "\n",
    "label_mapping = {label: index for index, label in enumerate(sorted_label)}\n",
    "print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog Breed의 개별 분포도 확인. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_df.shape)\n",
    "# breed 별 건수 확인\n",
    "data_df[['label', 'target']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 막대 그래프 형태로 breed별 건수 확인 \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minline\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# 막대 그래프 형태로 breed별 건수 확인 \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.figure(figsize=(26, 4))\n",
    "\n",
    "sns.countplot(data=data_df, x='label')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog Breed의 이미지 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# dog breed 별로 image를 보기 위한 utility 함수 생성.\n",
    "def show_grid_images(image_path_list, ncols=8, title=None):\n",
    "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
    "    for i in range(ncols):\n",
    "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].set_title(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()\n",
    "breed_image_list_02 = data_df[data_df['label']=='American_Staffordshire_terrier']['path'].iloc[:6].tolist()\n",
    "\n",
    "show_grid_images(breed_image_list_01, ncols=6, title='Staffordshire_bullterrier')\n",
    "show_grid_images(breed_image_list_02, ncols=6, title='American_Staffordshire_terrier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_df['label'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "breed_list = data_df['label'].value_counts().index.tolist()\n",
    "\n",
    "for iter_cnt, breed in enumerate(breed_list):\n",
    "    breed_image_list = data_df[data_df['label']==breed]['path'].iloc[:6].tolist()\n",
    "    show_grid_images(breed_image_list, ncols=6, title=breed)\n",
    "    if iter_cnt == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation 적용한 이미지 살펴 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# crop은 사용에 주의할것. 사람과 개가 같이 있으므로 center에 사람이 있을 경우 사람만 이미지가 잘릴수 있음. \n",
    "imsi_augmentor = A.Compose([\n",
    "    A.Resize(height=224, width=224, p=1), \n",
    "    A.CenterCrop(height=200, width=200, p=1),#A.CenterCrop(height=180, width=180, p=1)\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5)\n",
    "])\n",
    "\n",
    "# augmented 적용된 이미지를 보기 위해서 위에서 albumetation으로 image 변환 기법 적용된 transformer 입력\n",
    "# 이미지 사이즈를 224x224로 resize 적용. \n",
    "def show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n",
    "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
    "    for i in range(ncols):\n",
    "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
    "        if augmentor is not None:\n",
    "            image = augmentor(image=image)['image']\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(title) \n",
    "        \n",
    "breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()       \n",
    "show_grid_images(breed_image_list_01, augmentor=None, ncols=6, title='orignal Staffordshire_bullterrier')\n",
    "show_grid_images(breed_image_list_01, augmentor=imsi_augmentor, ncols=6, title='augmented Staffordshire_bullterrier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 DataFrame을 학습과 테스트용 DataFrame으로 분리. 학습 DataFrame은 다시 학습과 검증용으로 분리 \n",
    "* train_test_split()을 이용하여 전체의 40%를 테스트 데이터로 할당. stratify인자로 breed label별로 균등하게 할당 설정. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 전체 데이터의 60%를 학습, 40%를 테스트로 분리. \n",
    "train_df, test_df = train_test_split(data_df, test_size=0.4, stratify=data_df['label'], random_state=2025)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(train_df['label'].value_counts()/train_df.shape[0])\n",
    "print(test_df['label'].value_counts()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 다시 학습 데이터의 80%를 학습, 20%를 검증으로 분리\n",
    "tr_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['target'], random_state=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset와 DataLoader 생성\n",
    "* augmentation은 light한 augmention 부터 시작하여 점차 강도를 높임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "class BreedDataset(Dataset):\n",
    "    # 이미지 파일리스트, 타겟 파일리스트, transforms 등 이미지와 타겟 데이터 가공에 필요한 인자들을 입력 받음\n",
    "    def __init__(self, image_paths, targets=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    # 전체 건수를 반환\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    # idx로 지정된 하나의 image, label을 tensor 형태로 반환\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        # opencv로 이미지 파일 로딩\n",
    "        image_np = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        # 보통은 transform이 None이 되는 경우는 거의 없음(Tensor 변환이라도 있음)\n",
    "        image = self.transform(image=image_np)['image']\n",
    "\n",
    "        if self.targets is not None:\n",
    "            # 개별 target값을 tensor로 변환.\n",
    "            target = torch.tensor(self.targets[idx])\n",
    "            return image, target\n",
    "        # 테스트 데이터의 경우 targets가 입력 되지 않을 수 있으므로 이를 대비. \n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "class CFG:\n",
    "    batch_size = 16\n",
    "    image_size = 224\n",
    "\n",
    "# Data Augmentation\n",
    "tr_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size, p=1),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "def create_tr_val_loader(tr_df, val_df, tr_transform, val_transform):\n",
    "    tr_dataset =BreedDataset(image_paths=tr_df['path'].to_list(), \n",
    "                               targets=tr_df['target'].to_list(), transform=tr_transform)\n",
    "    val_dataset = BreedDataset(image_paths=val_df['path'].to_list(), \n",
    "                               targets=val_df['target'].to_list(), transform=val_transform)\n",
    "    \n",
    "    tr_loader = DataLoader(tr_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4*BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return tr_loader, val_loader\n",
    "\n",
    "tr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, \n",
    "                                             tr_transform=tr_transform, val_transform=val_transform)\n",
    "images, labels = next(iter(tr_loader))\n",
    "print(images.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision Model 생성.\n",
    "* Resnet101과 Efficientnet 계열을 테스트 할 수 있도록 모델 생성 함수 생성.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def create_tv_model(model_name, num_classes=1000):\n",
    "    model = None\n",
    "    if model_name == 'efficientnet_v2_s':\n",
    "        model = models.efficientnet_v2_s(weights='DEFAULT')\n",
    "        model.classifier = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                         nn.Linear(in_features=1280, out_features=num_classes))\n",
    "    elif model_name == 'efficientnet_b4':\n",
    "        model = models.efficientnet_b4(weights='DEFAULT')\n",
    "        model.classifier = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                         nn.Linear(in_features=1792, out_features=num_classes))\n",
    "    elif model_name == 'efficientnet_b1':\n",
    "        model = models.efficientnet_b1(weights='DEFAULT')\n",
    "        model.classifier = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                         nn.Linear(in_features=1280, out_features=num_classes))\n",
    "    elif model_name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights='DEFAULT')\n",
    "        model.classifier = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                         nn.Linear(in_features=1280, out_features=num_classes))\n",
    "    elif model_name == 'resnet101':\n",
    "        model = models.resnet101(weights='DEFAULT')\n",
    "        model.fc = nn.Linear(in_features=2048, out_features=num_classes)\n",
    "        \n",
    "    return model\n",
    "\n",
    "eff_model = create_tv_model('efficientnet_b0', num_classes=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "models.resnet101(weights=None)#resnet101, efficientnet_b0, efficientnet_v2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models.ResNet101_Weights.IMAGENET1K_V2.transforms() # EffcientNet_B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer로 모델 학습. \n",
    "* resnet101과 efficientnet B0/B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# /kaggle/working/modular/v1 디렉토리에 utils.py 파일 다운로드\n",
    "!rm -rf ./modular/v1\n",
    "!mkdir -p ./modular/v1\n",
    "!wget -O ./modular/v1/utils.py https://raw.githubusercontent.com/chulminkw/CNN_PG_Torch/main/modular/v1/utils.py?raw=true\n",
    "!ls ./modular/v1\n",
    "\n",
    "import sys\n",
    "\n",
    "# 반드시 system path를 아래와 같이 잡아줘야 함. \n",
    "sys.path.append('/kaggle/working')\n",
    "\n",
    "#아래가 수행되는지 반드시 확인\n",
    "from modular.v1.utils import Trainer, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "CFG.batch_size = 32 # 16\n",
    "CFG.image_size = 224\n",
    "\n",
    "# Horizontal_flip\n",
    "tr_transform_01 = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size, p=1),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "#learning_rate, callbacks, epochs는 인자로 입력\n",
    "def train_breed(model_name, tr_transform, val_transform, learning_rate=1e-3, callbacks=None, epochs=30):\n",
    "    tr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, \n",
    "                                             tr_transform=tr_transform, val_transform=val_transform)\n",
    "    model = create_tv_model(model_name, num_classes=120)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer=optimizer, mode='min', factor=0.2, patience=3, threshold=0.01, min_lr=1e-7)\n",
    "    \n",
    "    trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "                   train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, \n",
    "                   callbacks=callbacks, device=device)\n",
    "    # 학습 및 평가. epochs는 20회로 조정. \n",
    "    history = trainer.fit(epochs)\n",
    "    \n",
    "    return trainer, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#모델은 resnet101, HorizontalFlip만 augmentation적용. learning_rate는 1e-4, callbacks는 None, epochs는 30회 수행. \n",
    "trainer, history = train_breed('resnet101', tr_transform_01, val_transform, learning_rate=1e-4, \n",
    "                               callbacks=None, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#아래가 수행되는지 반드시 확인\n",
    "from modular.v1.utils import Predictor\n",
    "\n",
    "test_image_paths = test_df['path'].to_list()\n",
    "test_targets = test_df['target'].to_list()\n",
    "\n",
    "#CFG.batch_size = 16\n",
    "CFG.image_size = 224\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_dataset = BreedDataset(image_paths=test_image_paths, \n",
    "                            targets=test_targets, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "trained_model = trainer.get_trained_model()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어떤 Breed가 예측이 많이 틀렸는지 확인 \n",
    "* 실제 Ground Truth Breed와 예측 Breed가 어떻게 틀려졌는지 확인. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 모든 테스트 데이터에 대해서 예측 수행 후 numpy로 반환 \n",
    "def get_all_predictions(predictor, test_loader):\n",
    "    preds_all_list = []\n",
    "    targets_all_list = []\n",
    "    \n",
    "    for images, targets in test_loader:\n",
    "        preds = predictor.predict(images).cpu().numpy()\n",
    "        # 개별 원소값으로 저장해야 하므로 append()가 아니라 extend()로 list에 저장. \n",
    "        preds_all_list.extend(preds)\n",
    "        # targets_all_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    preds_all = np.array(preds_all_list)\n",
    "\n",
    "    return preds_all\n",
    "\n",
    "preds_all = get_all_predictions(predictor, test_loader)\n",
    "\n",
    "#예측 결과를 test_df의 별도 컬럼으로 저장. \n",
    "test_df['resnet101_pred'] = preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 예측이 틀린 데이터 확인 \n",
    "test_df[test_df['target'] != test_df['resnet101_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df[test_df['target'] != test_df['resnet101_pred']]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df[test_df['label'] == 'Eskimo_dog'][['target', 'resnet101_pred']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sorted_label = np.sort(data_df['label'].unique())\n",
    "#print(sorted_label)\n",
    "print(sorted_label[[24, 64, 101]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n",
    "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
    "    for i in range(ncols):\n",
    "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        if augmentor is not None:\n",
    "            image = augmentor(image=image)['image']\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(title) \n",
    "        \n",
    "breed_image_list_01 = data_df[data_df['label']=='Siberian_husky']['path'].iloc[:6].tolist()\n",
    "breed_image_list_02 = data_df[data_df['label']=='Eskimo_dog']['path'].iloc[:6].tolist()\n",
    "\n",
    "show_grid_images(breed_image_list_01, ncols=6, title='Siberian_husky')\n",
    "show_grid_images(breed_image_list_02, ncols=6, title='Eskimo_dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "wrong_result_df = test_df[test_df['target'] != test_df['resnet101_pred']]\n",
    "\n",
    "plt.figure(figsize=(26, 4))\n",
    "plt.xticks(rotation=90)\n",
    "sns.countplot(data=wrong_result_df, x='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### efficient b0로 모델 학습/평가\n",
    "* 동일한 batch size, image size, augmentation으로 efficientnet_b0 모델 학습 및 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models.EfficientNet_B0_Weights.IMAGENET1K_V1.transforms() # EffcientNet_B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "# 동일한 batch size, image size, augmentation으로 efficientnet_b0 모델 학습 및 평가. \n",
    "trainer, history = train_breed('efficientnet_b0', tr_transform_01, val_transform, learning_rate=1e-4, \n",
    "                               callbacks=None, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trained_model = trainer.get_trained_model()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNet B1 으로 학습/평가\n",
    "* image size를 240으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models.EfficientNet_B1_Weights.IMAGENET1K_V2.transforms() # EffcientNet_B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "CFG.batch_size = 32 # 16\n",
    "CFG.image_size = 240\n",
    "\n",
    "# Horizontal_flip\n",
    "tr_transform_01 = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size, p=1),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "trainer, history = train_breed('efficientnet_b1', tr_transform_01, val_transform, learning_rate=1e-4, \n",
    "                               callbacks=None, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#아래가 수행되는지 반드시 확인\n",
    "from modular.v1.utils import Predictor\n",
    "\n",
    "# 테스트 이미지 사이즈를 240으로 증가. \n",
    "CFG.image_size = 240\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_dataset = BreedDataset(image_paths=test_image_paths, \n",
    "                            targets=test_targets, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "trained_model = trainer.get_trained_model()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 Augmentation을 적용하여 모델 학습 및 성능 평가\n",
    "* Heavy한 Augmentation을 적용한다고 반드시 성능이 향상되는 것이 아님(오히려 성능이 저하될 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "\n",
    "CFG.batch_size = 32 # 16\n",
    "CFG.image_size = 240\n",
    "\n",
    "# Horizontal_flip\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "import timm\n",
    "\n",
    "CFG.batch_size = 32 # 16\n",
    "CFG.image_size = 240\n",
    "\n",
    "tr_transform_02 = A.Compose([\n",
    "    A.RandomResizedCrop(height=180, width=180, scale=(0.5, 1.0), p=0.3),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.VerticalFlip(p=0.3),\n",
    "    A.ShiftScaleRotate(p=0.2),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
    "    A.ColorJitter(p=0.2),\n",
    "    A.OneOf(\n",
    "        [A.CoarseDropout(p=1, max_holes=26), \n",
    "         A.CLAHE(p=1)\n",
    "        ], p=0.3), \n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()       \n",
    "show_grid_images(breed_image_list_01, augmentor=None, ncols=6, title='orignal Staffordshire_bullterrier')\n",
    "show_grid_images(breed_image_list_01, augmentor=tr_transform_02, ncols=6, title='augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer, history = train_breed('efficientnet_b1', tr_transform_02, val_transform, learning_rate=1e-4, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#아래가 수행되는지 반드시 확인\n",
    "from modular.v1.utils import Predictor\n",
    "\n",
    "test_image_paths = test_df['path'].to_list()\n",
    "test_targets = test_df['target'].to_list()\n",
    "\n",
    "# 테스트 이미지 사이즈를 240으로 증가. \n",
    "CFG.image_size = 240\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG.image_size, CFG.image_size),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_dataset = BreedDataset(image_paths=test_image_paths, \n",
    "                            targets=test_targets, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "trained_model = trainer.get_trained_model()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다른 Augumentation 적용 후 모델 학습 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tr_transform_03 = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.2, rotate_limit=30),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
    "    A.ColorJitter(p=0.2),\n",
    "    A.Resize(CFG.image_size, CFG.image_size, p=1),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()       \n",
    "show_grid_images(breed_image_list_01, augmentor=None, ncols=6, title='orignal Staffordshire_bullterrier')\n",
    "show_grid_images(breed_image_list_01, augmentor=tr_transform_03, ncols=6, title='augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer, history = train_breed('efficientnet_b1', tr_transform_03, val_transform, learning_rate=1e-4, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trained_model = trainer.get_trained_model()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
