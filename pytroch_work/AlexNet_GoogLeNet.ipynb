{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### AlexNet 구현\n* https://pytorch.org/vision/main/_modules/torchvision/models/alexnet.html 에서 가져옴","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass AlexNet(nn.Module):\n    def __init__(self, num_classes: int = 1000, dropout: float = 0.5) -> None:\n        super().__init__()\n        self.features = nn.Sequential(\n            # nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            # nn.Conv2d(96, 256, kernel_size=5, padding=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            # nn.Conv2d(256, 384, kernel_size=3, padding=1), \n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(384, 384, kernel_size=3, padding=1),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            # nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchinfo import summary\n\nalexnet_model = AlexNet()\n\nsummary(model=alexnet_model, input_size=(1, 3, 227, 227),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### GoogLeNet 구현\n* Inception Block을 먼저 구현한 뒤, 9개의 Inception Block을 이어서 구현\n* 최종 Classifier Layer 이외에 2개의 보조 Classifier Layer 존재\n* https://github.com/pytorch/vision/blob/main/torchvision/models/googlenet.py\n","metadata":{}},{"cell_type":"markdown","source":"#### Inception Block 구현\n![Inception Block](https://github.com/chulminkw/CNN_PG_Torch/blob/main/image/inception_module.png?raw=true)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Conv -> BN -> Relu 연속 적용. \nclass BasicConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,  \n                              kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\n\nclass InceptionBlock(nn.Module):\n    '''\n    in_channels: 입력 Feature Map 채널 수\n    ch_1x1: 단독 1x1 필터수\n    ch_3x3_reduce: 3x3 Conv 적용 전 1x1 Conv 필터수\n    ch_3x3: 3x3 Conv 필터수\n    ch_5x5_reduce: 5x5 Conv 적용 전 1x1 Conv 필터수\n    ch_5x5: 5x5 Conv 필터수\n    pool_prj: MaxPooling 적용 후 1x1 Conv 필터수 \n    '''\n    def __init__(self, in_channels, ch_1x1, ch_3x3_reduce, ch_3x3, ch_5x5_reduce, ch_5x5, pool_prj): \n        super().__init__()\n        # 첫번째 1x1 Conv branch\n        self.branch1 = BasicConv2d(in_channels, ch_1x1, kernel_size=1)\n        # 3x3 적용 전 1x1 conv -> 3x3 Conv\n        self.branch2 = nn.Sequential(\n            BasicConv2d(in_channels, ch_3x3_reduce, kernel_size=1), \n            BasicConv2d(ch_3x3_reduce, ch_3x3, kernel_size=3, padding=1))\n        # 5x5 적용 전 1x1 Conv -> 3x3 Conv. \n        self.branch3 = nn.Sequential(\n            BasicConv2d(in_channels, ch_5x5_reduce, kernel_size=1),\n            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n            # Please see https://github.com/pytorch/vision/issues/906 for details.\n            BasicConv2d(ch_5x5_reduce, ch_5x5, kernel_size=3, padding=1))\n        # Max Pooling 후 1x1 적용\n        self.branch4 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n            BasicConv2d(in_channels, pool_prj, kernel_size=1))\n\n    def forward(self, x):\n        branch1 = self.branch1(x)\n        branch2 = self.branch2(x)\n        branch3 = self.branch3(x)\n        branch4 = self.branch4(x)\n        # 단독 1x1 결과, 3x3 결과, 5x5 결과, pool이후 1x1 결과 feature map을 채널 기준으로 Concat 적용. \n        return torch.cat([branch1, branch2, branch3, branch4], 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### MaxPool2d ceil_mode=True\ninput_tensor = torch.rand(1, 3, 28, 28)\nmaxpool_01 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True)# False로 변경 테스트\noutput_01 = maxpool_01(input_tensor)\nprint(output_01.shape)\n\nmaxpool_02 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)# False, padding=1로 변경 테스트,\noutput_02 = maxpool_02(input_tensor)\nprint(output_02.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchinfo import summary\n\n#InceptionBlock 생성자(in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool_prj)\ninception_3a = InceptionBlock(in_channels=192, ch_1x1=64, ch_3x3_reduce=96, ch_3x3=128, \n                               ch_5x5_reduce=16, ch_5x5=32, pool_prj=32)\nsummary(model=inception_3a, input_size=(1, 192, 28, 28),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 보조 Classifier 생성\n![AUX](https://github.com/chulminkw/CNN_PG_Torch/blob/main/image/Googlenet_network.png?raw=true)","metadata":{}},{"cell_type":"code","source":"class AuxClassifier(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n        self.conv1 = BasicConv2d(in_channels, 128, kernel_size=1)\n        self.fc = nn.Sequential(\n            nn.Linear(4*4*128, 1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p=0.7),\n            nn.Linear(1024, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.avgpool(x)\n        x = self.conv1(x)\n        x = torch.flatten(x, 1)\n        return self.fc(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### GoogLeNet 생성\n* 앞에서 생성한 InceptionBlock과 AuxClassifier를 활용하여 GoogLeNet 생성\n* 아래는 GooLeNet 구성\n![AUX](https://github.com/chulminkw/CNN_PG_Torch/blob/main/image/Googlenet_Diagram.png?raw=true)","metadata":{}},{"cell_type":"code","source":"class GoogLeNet(nn.Module):\n    def __init__(self, num_classes=1000, aux_logits=True, dropout=0.2):\n        super().__init__()\n\n        self.aux_logits = aux_logits\n        self.training = True\n        \n        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n        \n        # InceptionBlock 생성자(in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool)\n        # 처음 2개의 Inception Block\n        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n        \n        # InceptionBlock 생성자(in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool)\n        # 5개의 Inception Block\n        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n\n        # InceptionBlock 생성자(in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool)\n        # 5개의 Inception Block\n        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n\n        if aux_logits:\n            self.aux1 = AuxClassifier(512, num_classes)\n            self.aux2 = AuxClassifier(528, num_classes)\n        else:\n            self.aux1 = None\n            self.aux2 = None\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(p=dropout)\n        self.fc = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.maxpool2(x)\n        \n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool3(x)\n\n        x = self.inception4a(x)\n        # 보조 classifier 출력\n        if self.training:\n            out1 = self.aux1(x)\n\n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        # 보조 classifier 출력\n        if self.training:\n            out2 = self.aux2(x)\n\n        x = self.inception4e(x)\n        x = self.maxpool4(x)\n\n        x = self.inception5a(x)\n        x = self.inception5b(x)\n\n        x = self.avgpool(x)\n\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)                \n        if self.training:\n            return [x, out1, out2] # 최종 Classifier외의 2개의 보조(Auxiliary) classifier 출력을 모두 list형태로 출력\n        else:\n            return x\n\ndef set_train(self):\n        self.training = True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchinfo import summary\n\ngooglenet_model = GoogLeNet(num_classes=1000, aux_logits=True, dropout=0.2)\nsummary(model=googlenet_model, input_size=(1, 3, 224, 224),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import models\n\ntv_googlenet_model = models.googlenet(weights=None)\n\nsummary(model=tv_googlenet_model, input_size=(1, 3, 224, 224),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}