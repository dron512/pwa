{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### torchvision Pretrained models\r\n* torchvision은 많은 CNN 최신 모델들을 가지고 있으며, 이들 모델들을 ImageNet 데이터 세트를 학습하여 Weight를 가지고 있음. \r\n* 이들 최신 모델을 이용하여 간단하게 Custom 모델을 만들 수 있음.\r\n* https://pytorch.org/vision/main/models.html 에서 모델 리스트를 확인해 볼 수 있음.","metadata":{}},{"cell_type":"markdown","source":"### torchvision의 models 모듈 활용하기","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import models\n\nprint(torchvision.__version__)\n\n# 현 torchvision 버전에서 사용 가능한 model들의 리스트\nmodels.list_models() # include 또는 exclude로 model 리스트 필터링 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 특정 모델이 가지고 있는 weight의 종류를 확인. 하나의 모델은 학습 데이터 세트, 학습 방식에 따라 여러개의 weights를 가질 수 있음. \nweights_enum = models.get_model_weights(name='resnet50') #'efficientnet_b1'\nprint([weight for weight in weights_enum])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 모든 모델이 가지고 있는 weights 들의 list 출력\nall_models = models.list_models()\nfor model_name in all_models:\n    weights = models.get_model_weights(name=model_name)\n    if weights:\n        print(f\"Model: {model_name}, Weights: {[weight for weight in weights]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### torchvision models의 Pretrained 모델 로드하기\n* 과거 버전에서는 models.model명(pretrained=True)를 이용하여 pretrained 학습된 모델을 가져올 수 있음.\n* 현 버전에서는 동일 모델이더라도 pretrained된 weight를 지정해서 모델을 생성하도록 변경됨. ","metadata":{}},{"cell_type":"code","source":"#과거 버전은 pretrained=True를 이용하여 미리 pretrained된 weight가 설정된 모델을 가져올 수 있었지만, torchvision 0.13 부터 deprecated됨. \nmodel_temp = models.vgg19_bn(pretrained=True) #pretrained=False이면 pretrained된 weight를 가져오지 않음. resnet50, efficientnet-b0, resnext101_32x8d\nprint(model_temp)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print([weight for weight in models.get_model_weights('vgg19_bn')])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torchvision.models import VGG19_Weights, VGG19_BN_Weights\n\n# batch normalization이 적용된 모델 가져오기\nprint([weight for weight in models.get_model_weights('vgg19_bn')])\nvgg_model = models.vgg19_bn(weights=models.VGG19_BN_Weights.IMAGENET1K_V1) #weights='IMAGENET1K_V1' 또는 'DEFAULT'\nprint(vgg_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchinfo import summary\n\nsummary(model=vgg_model, input_size=(1, 3, 418, 418), #(1, 3, 32, 32)\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# resnet 모델 가져오기\nprint([weight for weight in models.get_model_weights('resnet50')])\nresnet_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)#weights='IMAGENET1K_V2' 또는 'DEFAULT'\nprint(resnet_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Classfication Layer를 변경하여 Custom 모델 만들기\n* torchvision의 CNN 분류 모델들은 대부분 ImageNet 데이터를 판별하기 위해 만들어짐. ImageNet 데이터는 Class의 갯수가 1000개 이므로 최종 classification layer의 output 이 1000개로 되어 있음.\n* Class의 갯수가 1000개가 아닌 Custom Dataset을 판별하는 모델을 위해서는 마지막 Classification Layer의 output을 Class의 갯수에 맞춰서 customization 하여 모델을 생성할 필요가 있음.\n* torchvision models의 최종 classifier layer(또는 block)의 변수명은 (거의 대부분)classifier 또는 fc이며, 이들 변수명에 직접 custom classifier layer를 할당하여 변경 ","metadata":{}},{"cell_type":"code","source":"vgg_model.classifier # resnet_model.fc\n# resnet_model.fc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sequential block으로 classifier가 설정되어 있는 경우\n* 맨 마지막 Classifier Linear Layer만 출력 features를 class 갯수로 가지는 Layer로 변경\n* 전체 Sequential Block을 새롭게 교체","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nNUM_CLASSES = 10\n\n# 직접 model의 최종 classifier 지정하여 변경할 수 있음.\nvgg_model.classifier = nn.Sequential(\n      nn.Linear(in_features=25088, out_features=4096, bias=True),\n      nn.ReLU(inplace=True),\n      nn.Dropout(p=0.5, inplace=False),\n      nn.Linear(in_features=4096, out_features=4096, bias=True),\n      nn.ReLU(inplace=True),\n      nn.Dropout(p=0.5, inplace=False), \n      nn.Linear(in_features=4096, out_features=NUM_CLASSES, bias=True)\n)\n\n# Sequential을 새롭게 정의\n# vgg_model.classifier = nn.Sequential(\n#     nn.Linear(in_features=25088, out_features=4096, bias=True),\n#     nn.ReLU(inplace=True),\n#     nn.Dropout(p=0.5, inplace=False),\n#     nn.Linear(in_features=4096, out_features=500, bias=True),\n#     nn.ReLU(inplace=True),\n#     nn.Dropout(p=0.5, inplace=False),\n#     nn.Linear(in_features=500, out_features=NUM_CLASSES, bias=True)\n# )\n\nprint(vgg_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vgg_model.classifier[6]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUM_CLASSES = 10\n# Sequential 내에서 최종 layer만 변경. \n#vgg_model.classifier[6] = nn.Linear(in_features=4096, out_features=NUM_CLASSES)\n# 보통은 아래와 같이 in_features값을 최종 layer의 in_features로 직접 가져와서 생성.\nnum_in_features = vgg_model.classifier[6].in_features\nvgg_model.classifier[6] == nn.Linear(in_features=num_in_features, out_features=NUM_CLASSES)\nprint(vgg_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# resnet의 경우 최종 classifier의 변수명이 fc임. out_features가 10인 Linear Layer로 변경. \nnum_in_features = resnet_model.fc.in_features\nresnet_model.fc = nn.Linear(in_features=num_in_features, out_features=NUM_CLASSES)\n#resnet_model.fc = nn.Linear(in_features=2048, out_features=10, bias=True)\nprint(resnet_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 또는 아예 최종 layer 구조를 변경\nresnet_model.fc = nn.Sequential(\n                    nn.Dropout(0.5),\n                    nn.Linear(in_features=2048, out_features=512),\n                    nn.ReLU(),\n                    nn.Dropout(0.3),\n                    nn.Linear(in_features=512, out_features=128),\n                    nn.ReLU(),\n                    nn.Dropout(0.2),\n                    nn.Linear(in_features=128, out_features=NUM_CLASSES)\n)\nprint(resnet_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pretrained Model(Weights)에 적용된 기본 transforms 확인하기\n* Weights 객체에 transforms() 메소드를 호출하여 pretrained 모델에 적용된 기본 transforms들을 확인\n* Pretrained Model에서 inference 수행시 입력 이미지 사이즈 설정시 활용","metadata":{}},{"cell_type":"code","source":"from torchvision import models\n\nresnet_weights = models.ResNet50_Weights.IMAGENET1K_V2# 또는 ResNet50_Weights.DEFAULT\nresnet_transforms = resnet_weights.transforms()\n\nprint(resnet_transforms)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 개와 고양이 판별 모델을 Pretrained Model을 기반으로 수행. ","metadata":{}},{"cell_type":"markdown","source":"#### Custom Model 생성 함수 만들기","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndef create_vgg_model(model_name, num_classes=10):\n    model = None\n    if model_name == 'vgg16_bn':\n        model = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n    elif model_name == 'vgg19_bn':\n        model = models.vgg19_bn(weights=models.VGG19_BN_Weights.IMAGENET1K_V1)\n    \n    num_in_features = model.classifier[6].in_features\n    model.classifier[6] = nn.Linear(in_features=num_in_features, out_features=num_classes)\n\n    return model\n\ndef create_resnet_model(model_name, num_classes=10):\n    model = None\n    if model_name == 'resnet50':\n        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n    elif model_name == 'resnet101':\n        model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2)\n    \n    num_in_features = model.fc.in_features\n    model.fc = nn.Linear(in_features=num_in_features, out_features=num_classes)\n\n    return model\n    \nresnet_model = create_resnet_model('resnet50', num_classes=2) #resnet50, resnet101\nprint(resnet_model)\n\n# summary(model=resnet_model, input_size=(1, 3, 224, 224), #(1, 3, 64, 64)\n#         col_names=['input_size', 'output_size', 'num_params'], \n#         row_settings=['var_names'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 개와 고양이 Dataset 및 DataLoader 생성","metadata":{}},{"cell_type":"markdown","source":"#### 개와 고양이 데이터 다운로드 및 메타 데이터 생성","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.model_selection import train_test_split\n\npaths = [] # 이미지 파일 경로 리스트\ndataset_gubuns = [] # train/test 구분 리스트\nlabel_gubuns = [] #강아지/고양이 리스트\n\n# os.walk()를 이용하여 특정 디렉토리 밑에 있는 모든 하위 디렉토리를 모두 조사. \n# cat-and-dog 하위 디렉토리 밑에 jpg 확장자를 가진 파일이 모두 이미지 파일임\n# cat-and-dog 밑으로 /train/, /test/ 하위 디렉토리 존재(학습, 테스트 용 이미지 파일들을 가짐)\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n        if '.jpg' in filename:\n            # 파일의 절대 경로를 file_path 변수에 할당. \n            file_path = dirname+'/'+ filename\n            paths.append(file_path)\n            # 파일의 절대 경로에 training_set, test_set가 포함되어 있으면 데이터 세트 구분을 'train'과 'test'로 분류. \n            if '/training_set/' in file_path:\n                dataset_gubuns.append('train')  \n            elif '/test_set/' in file_path:\n                dataset_gubuns.append('test')\n            else: dataset_gubuns.append('N/A')\n            \n            # 파일의 절대 경로에 dogs가 있을 경우 해당 파일은 dog 이미지 파일이고, cats일 경우는 cat 이미지 파일임. \n            if 'dogs' in file_path:\n                label_gubuns.append('DOG')\n            elif 'cats' in file_path:\n                label_gubuns.append('CAT')\n            else: label_gubuns.append('N/A')\n# DataFrame 메타 데이터 생성. \ndata_df = pd.DataFrame({'path':paths, \n                        'dataset':dataset_gubuns, \n                        'label':label_gubuns})\n# Target값 0, 1 변환\nlabel_mapping = {'DOG': 0, 'CAT': 1}\ndata_df['target'] = data_df['label'].map(label_mapping)\n\n# 전체 데이터 세트에서 학습과 테스트용 메타 정보 DataFrame 생성. \ntrain_df = data_df[data_df['dataset']=='train']\ntest_df = data_df[data_df['dataset']=='test']\n# 기존 학습 DataFrame을 다시 학습과 검증 DataFrame으로 분할. 85%가 학습, 15%가 검증 \ntr_df, val_df = train_test_split(train_df, test_size=0.15, stratify=train_df['target'], random_state=2025)\n\nprint(data_df.shape, train_df.shape, tr_df.shape, val_df.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Dataset 및 학습/검증용 DataLoader 생성","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nfrom PIL import Image\n\nclass CnD_Dataset(Dataset):\n    # 이미지 파일리스트, 타겟 파일리스트, transforms 등 이미지와 타겟 데이터 가공에 필요한 인자들을 입력 받음\n    def __init__(self, image_paths, targets=None, transform=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n    \n    # 전체 건수를 반환\n    def __len__(self):\n        return len(self.image_paths)\n        \n    # idx로 지정된 하나의 image, label을 tensor 형태로 반환\n    def __getitem__(self, idx):    \n        # PIL을 이용하여 이미지 로딩하고 PIL Image 객체 반환.\n        pil_image = Image.open(self.image_paths[idx])\n        # 보통은 transform이 None이 되는 경우는 거의 없음(Tensor 변환이라도 있음)\n        image = self.transform(pil_image)\n\n        if self.targets is not None:\n            # 개별 target값을 tensor로 변환.\n            target = torch.tensor(self.targets[idx])\n            return image, target\n        # 테스트 데이터의 경우 targets가 입력 되지 않을 수 있으므로 이를 대비. \n        else:\n            return image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms as T\n\nBATCH_SIZE = 16\nIMG_SIZE = 224\nIMG_MEANS = [0.485, 0.456, 0.406] # ImageNet 데이터세트의 이미지 채널별 평균값\nIMG_STD = [0.229, 0.224, 0.225] # ImageNet 데이터세트의 이미지 채널별 표준편차값\n\ndef create_tr_val_loader(tr_df, val_df, transform):\n    tr_dataset = CnD_Dataset(image_paths=tr_df['path'].to_list(), \n                            targets=tr_df['target'].to_list(), transform=transform)\n    val_dataset = CnD_Dataset(image_paths=val_df['path'].to_list(), \n                            targets=val_df['target'].to_list(), transform=transform)\n    tr_loader = DataLoader(tr_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=2*BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\n    return tr_loader, val_loader\n\ntransform_01 = T.Compose([\n            T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n            T.ToTensor(), T.Normalize(mean=IMG_MEANS, std=IMG_STD)\n])\n\ntr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=transform_01)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Trainer Class 생성 ","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.nn.functional as F\n\nclass Trainer:\n    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, device=None):\n        self.model = model.to(device)\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        # scheduler 추가\n        self.scheduler = scheduler\n        self.device = device\n        # 현재 learning rate 변수 추가\n        self.current_lr = self.optimizer.param_groups[0]['lr']\n\n    def train_epoch(self, epoch):\n        self.model.train()\n\n        # running 평균 loss 계산.\n        accu_loss = 0.0\n        running_avg_loss = 0.0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        # tqdm으로 실시간 training loop 진행 상황 시각화\n        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n                # 반드시 to(self.device). to(device) 아님.\n                inputs = inputs.to(self.device)\n                targets = targets.to(self.device)\n\n                # Forward pass\n                outputs = self.model(inputs)\n                loss = self.loss_fn(outputs, targets)\n\n                # Backward pass\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                accu_loss += loss.item()\n                running_avg_loss = accu_loss /(batch_idx + 1)\n\n                # accuracy metric 계산\n                # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                num_correct = (outputs.argmax(-1) == targets).sum().item()\n                # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산\n                num_total += inputs.shape[0]\n                accu_num_correct += num_correct\n                accuracy = accu_num_correct / num_total\n\n                #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                progress_bar.update(1)\n                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                              \"Accuracy\": accuracy})\n\n        if not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            self.scheduler.step()\n            self.current_lr = self.scheduler.get_last_lr()[0]\n\n        return running_avg_loss, accuracy\n\n    def validate_epoch(self, epoch):\n        if not self.val_loader:\n            return None\n\n        self.model.eval()\n\n        # running 평균 loss 계산.\n        accu_loss = 0\n        running_avg_loss = 0\n        # 정확도, 정확도 계산을 위한 전체 건수 및 누적 정확건수\n        num_total = 0.0\n        accu_num_correct = 0.0\n        accuracy = 0.0\n        \n        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n\n                    outputs = self.model(inputs)\n\n                    loss = self.loss_fn(outputs, targets)\n                    # batch 반복 시 마다 누적  loss를 구하고 이를 batch 횟수로 나눠서 running 평균 loss 구함.\n                    accu_loss += loss.item()\n                    running_avg_loss = accu_loss /(batch_idx + 1)\n\n                    # accuracy metric 계산\n                    # outputs 출력 예측 class값과 targets값 일치 건수 구하고\n                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n                    # 배치별 누적 전체 건수와 누적 전체 num_correct 건수로 accuracy 계산\n                    num_total += inputs.shape[0]\n                    accu_num_correct += num_correct\n                    accuracy = accu_num_correct / num_total\n\n                    #tqdm progress_bar에 진행 상황 및 running 평균 loss와 정확도 표시\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # 20 batch 횟수마다 또는 맨 마지막 batch에서 update\n                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n                                                  \"Accuracy\":accuracy})\n        # scheduler에 검증 데이터 기반에서 epoch레벨로 계산된 loss를 입력해줌.\n        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n            self.scheduler.step(running_avg_loss)\n            self.current_lr = self.scheduler.get_last_lr()[0]\n\n        return running_avg_loss, accuracy\n\n    def fit(self, epochs):\n        # epoch 시마다 학습/검증 결과를 기록하는 history dict 생성. learning rate 추가\n        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n        for epoch in range(epochs):\n            train_loss, train_acc = self.train_epoch(epoch)\n            val_loss, val_acc = self.validate_epoch(epoch)\n            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n                  f\", Current lr:{self.current_lr:.6f}\")\n            # epoch 시마다 학습/검증 결과를 기록. learning rate 추가\n            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n            history['lr'].append(self.current_lr)\n\n        return history\n\n    # 학습이 완료된 모델을 return\n    def get_trained_model(self):\n        return self.model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import SGD, Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nNUM_INPUT_CHANNELS = 3\n# 개(target값 0)와 고양이(target값 1) 2개\nNUM_CLASSES = 2\n\nmodel = create_resnet_model('resnet50', num_classes=NUM_CLASSES) #resnet50, resnet101\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\noptimizer = Adam(model.parameters(), lr=0.001)\nloss_fn = nn.CrossEntropyLoss()\nscheduler = ReduceLROnPlateau(\n            optimizer=optimizer, mode='min', factor=0.5, patience=3, threshold=0.01, min_lr=0.00001)\n\ntrainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n       train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, device=device)\n# 학습 및 평가\nhistory = trainer.fit(30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Predictor 클래스 생성 및 평가. ","metadata":{}},{"cell_type":"code","source":"class Predictor:\n    def __init__(self, model, device):\n        self.model = model.to(device)\n        self.device = device\n\n    def evaluate(self, loader):\n        self.model.eval()\n        eval_metric = 0.0\n        \n        num_total = 0.0\n        accu_num_correct = 0.0\n\n        with tqdm(total=len(loader), desc=f\"[Evaluating]\", leave=True) as progress_bar:\n            with torch.no_grad():\n                for batch_idx, (inputs, targets) in enumerate(loader):\n                    inputs = inputs.to(self.device)\n                    targets = targets.to(self.device)\n                    pred = self.model(inputs)\n\n                    # 정확도 계산을 위해 누적 전체 건수와 누적 전체 num_correct 건수 계산  \n                    num_correct = (pred.argmax(-1) == targets).sum().item()\n                    num_total += inputs.shape[0]\n                    accu_num_correct += num_correct\n                    eval_metric = accu_num_correct / num_total\n\n                    progress_bar.update(1)\n                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n                        progress_bar.set_postfix({\"Accuracy\": eval_metric})\n        \n        return eval_metric\n\n    def predict_proba(self, inputs):\n        self.model.eval()\n        with torch.no_grad():\n            inputs = inputs.to(self.device)\n            outputs = self.model(inputs)\n            #예측값을 반환하므로 targets은 필요 없음.\n            #targets = targets.to(self.device)\n            pred_proba = F.softmax(outputs, dim=-1) #또는 dim=1\n\n        return pred_proba\n\n    def predict(self, inputs):\n        pred_proba = self.predict_proba(inputs)\n        pred_class = torch.argmax(pred_proba, dim=-1)\n\n        return pred_class","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = data_df[data_df['dataset']=='test']\ntest_image_paths = test_df['path'].to_list()\ntest_targets = test_df['target'].to_list()\n\nIMG_SIZE=224\ntransform_02 = T.Compose([\n                        T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n                        T.ToTensor(), \n                        T.Normalize(mean=[0.485, 0.456, 0.406], \n                                    std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = CnD_Dataset(image_paths=test_image_paths, \n                            targets=test_targets, transform=transform_02)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\ntrained_model = trainer.get_trained_model()\n\npredictor = Predictor(model=trained_model, device=device)\neval_metric = predictor.evaluate(test_loader)\nprint(f'test dataset evaluation:{eval_metric:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nprint(test_df['path'][0], test_df['target'][0], test_df['label'][0])\npil_image = Image.open(test_df['path'][0])\n\nplt.imshow(pil_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\nprint(test_df['path'][0], test_df['target'][0], test_df['label'][0])\npil_image = Image.open(test_df['path'][0])\n\npil_tensor = transform_02(pil_image)\npil_tensor = pil_tensor.unsqueeze(0)\n\npred_class = predictor.predict(pil_tensor).item()\nprint('predicted class:', pred_class)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 10개의 테스트 이미지로 예측 결과\nfor i in range(10):\n    pil_image = Image.open(test_df['path'][i])\n    pil_tensor = transform_02(pil_image).unsqueeze(0)\n    pred_class = predictor.predict(pil_tensor).item()\n    print('actual class:', test_df['target'][i],'predicted class:', pred_class)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}