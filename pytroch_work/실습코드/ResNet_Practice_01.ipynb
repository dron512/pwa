{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### ResNet 34 모델 살펴보기","metadata":{}},{"cell_type":"code","source":"from torchvision import models\n\nmodels.list_models(include='resnet*')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T00:21:56.666312Z","iopub.execute_input":"2025-01-14T00:21:56.666572Z","iopub.status.idle":"2025-01-14T00:22:00.645813Z","shell.execute_reply.started":"2025-01-14T00:21:56.666548Z","shell.execute_reply":"2025-01-14T00:22:00.645065Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50']"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from torchvision import models\n\nresnet34_model = models.resnet34(weights=None)\nprint(resnet34_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T00:57:22.411198Z","iopub.execute_input":"2025-01-14T00:57:22.411491Z","iopub.status.idle":"2025-01-14T00:57:22.743665Z","shell.execute_reply.started":"2025-01-14T00:57:22.411468Z","shell.execute_reply":"2025-01-14T00:57:22.742918Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from torchinfo import summary \n\nsummary(model=resnet34_model, input_size=(1, 3, 224, 224),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T00:57:27.611054Z","iopub.execute_input":"2025-01-14T00:57:27.611334Z","iopub.status.idle":"2025-01-14T00:57:28.480792Z","shell.execute_reply.started":"2025-01-14T00:57:27.611305Z","shell.execute_reply":"2025-01-14T00:57:28.479814Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"===================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #\n===================================================================================================================\nResNet (ResNet)                          [1, 3, 224, 224]          [1, 1000]                 --\n├─Conv2d (conv1)                         [1, 3, 224, 224]          [1, 64, 112, 112]         9,408\n├─BatchNorm2d (bn1)                      [1, 64, 112, 112]         [1, 64, 112, 112]         128\n├─ReLU (relu)                            [1, 64, 112, 112]         [1, 64, 112, 112]         --\n├─MaxPool2d (maxpool)                    [1, 64, 112, 112]         [1, 64, 56, 56]           --\n├─Sequential (layer1)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (0)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (1)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (2)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n├─Sequential (layer2)                    [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    └─BasicBlock (0)                    [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 128, 28, 28]          73,728\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─Sequential (downsample)      [1, 64, 56, 56]           [1, 128, 28, 28]          8,448\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─BasicBlock (1)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─BasicBlock (2)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─BasicBlock (3)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n├─Sequential (layer3)                    [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    └─BasicBlock (0)                    [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 256, 14, 14]          294,912\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─Sequential (downsample)      [1, 128, 28, 28]          [1, 256, 14, 14]          33,280\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (1)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (2)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (3)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (4)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (5)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n├─Sequential (layer4)                    [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    └─BasicBlock (0)                    [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 512, 7, 7]            1,179,648\n│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─Sequential (downsample)      [1, 256, 14, 14]          [1, 512, 7, 7]            132,096\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    └─BasicBlock (1)                    [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    └─BasicBlock (2)                    [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]            [1, 512, 1, 1]            --\n├─Linear (fc)                            [1, 512]                  [1, 1000]                 513,000\n===================================================================================================================\nTotal params: 21,797,672\nTrainable params: 21,797,672\nNon-trainable params: 0\nTotal mult-adds (G): 3.66\n===================================================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 59.82\nParams size (MB): 87.19\nEstimated Total Size (MB): 147.61\n==================================================================================================================="},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Resnet-34 Residual(Identity) Block(BasicBlock) 생성\n* 2개의 Conv block(3x3 Conv -> BN -> Relu -> 3x3 Conv -> BN)을 연속적으로 이어서 생성.\n* Residual BasicBlock에 입력 전 값을 입력 후 값과 Add 한 후 Relu 적용.\n* Stage별로 Feature map의 크기를 줄일 경우 첫번째 Conv에서 stride 2를 적용하여 줄임.\n* Feature map의 크기를 줄일 경우 downsample block을 이용하여 입력값의 크기 역시 절반으로 줄여서 add 할 수 있도록 함.\n  \n![Residual Block Base](https://github.com/chulminkw/CNN_PG_Torch/blob/main/image/residual_block.png?raw=true)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, last_channels, stride=1, downsample=None):\n        '''\n        입력 채널수, 최종 채널수\n        stride는 기본 1. stage 별로 feature map의 크기를 줄일 경우 2\n        downsample은 stride가 2일 경우 BasicBlock 입력 전 값도 1x1 conv, stride 2를 적용하여 사이즈를 줄이는 Conv block\n        '''\n        super().__init__()\n        self.conv_block = nn.Sequential(\n            # 첫번째 3x3 Conv. stage별로 Feature Map의 크기를 줄일 시 첫번째 Conv에서 줄임(3x3 kernel에 stride=2로)\n            nn.Conv2d(in_channels, last_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(last_channels),\n            nn.ReLU(),\n            # 두번째 3x3 Conv\n            nn.Conv2d(last_channels, last_channels, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(last_channels)\n        )\n        self.downsample = downsample\n\n    def forward(self, x):\n        identity = x\n        out = self.conv_block(x)\n        if self.downsample:\n            identity = self.downsample(x)\n            \n        out += identity\n        out = F.relu(out)\n        \n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:15:20.482455Z","iopub.execute_input":"2025-01-14T01:15:20.482760Z","iopub.status.idle":"2025-01-14T01:15:20.488425Z","shell.execute_reply.started":"2025-01-14T01:15:20.482717Z","shell.execute_reply":"2025-01-14T01:15:20.487554Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"basicblock = BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None)\nprint('## my basicblock ## \\n', basicblock)\nprint('## torchvision basicblock ##\\n', resnet34_model.layer1[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:15:25.595485Z","iopub.execute_input":"2025-01-14T01:15:25.595799Z","iopub.status.idle":"2025-01-14T01:15:25.602421Z","shell.execute_reply.started":"2025-01-14T01:15:25.595764Z","shell.execute_reply":"2025-01-14T01:15:25.601782Z"}},"outputs":[{"name":"stdout","text":"## my basicblock ## \n BasicBlock(\n  (conv_block): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)\n## torchvision basicblock ##\n BasicBlock(\n  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"stage_01 = nn.Sequential(\n    BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None),\n    BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None),\n    BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None)\n)\n\nprint('## my stage_01 ## \\n', stage_01)\nprint('## torchvision stage_01 ##\\n', resnet34_model.layer1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:15:29.363668Z","iopub.execute_input":"2025-01-14T01:15:29.363972Z","iopub.status.idle":"2025-01-14T01:15:29.374387Z","shell.execute_reply.started":"2025-01-14T01:15:29.363949Z","shell.execute_reply":"2025-01-14T01:15:29.373624Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"## my stage_01 ## \n Sequential(\n  (0): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (1): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (2): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n## torchvision stage_01 ##\n Sequential(\n  (0): BasicBlock(\n    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (1): BasicBlock(\n    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (2): BasicBlock(\n    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"#### 아래는 downsample을 적용하지 않을 경우 오류 발생. \n* stage의 첫번째 BasicBlock에 stride=2를 적용할 경우 downsample을 conv 1x1(in_channels, out_channels, stride=2) 으로 만들어 주지 않을 경우 오류 발생.\n* stage_02의 첫번째 Conv block에서 입력 feature map의 크기를 절반으로 줄이므로, stage_02 입력 전 feature map 크기의 절반으로 줄여야 add 할 수 있음. downsample 필요.  ","metadata":{}},{"cell_type":"code","source":"# downsample을 적용하지 않을 경우 입력값과 Residual Block의 shape가 같지 않아서 add시 오류 발생. \nstage_02 = nn.Sequential(\n    BasicBlock(in_channels=64, last_channels=128, stride=2, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None)\n)\n\nprint('## my stage_02 ## \\n', stage_02)\nprint('## torchvision stage_02 ##\\n', resnet34_model.layer2)\n\nsummary(model=stage_02, input_size=(1, 64, 56, 56),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:24:32.851618Z","iopub.execute_input":"2025-01-14T01:24:32.851930Z","iopub.status.idle":"2025-01-14T01:24:32.891319Z","shell.execute_reply.started":"2025-01-14T01:24:32.851905Z","shell.execute_reply":"2025-01-14T01:24:32.890286Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"## my stage_02 ## \n Sequential(\n  (0): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (1): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (2): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (3): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n## torchvision stage_02 ##\n Sequential(\n  (0): BasicBlock(\n    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (1): BasicBlock(\n    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (2): BasicBlock(\n    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (3): BasicBlock(\n    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-f2dec6819b06>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (56) at non-singleton dimension 3","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-76b7fecb2ded>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'## torchvision stage_02 ##\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet34_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m summary(model=stage_02, input_size=(1, 64, 56, 56),\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcol_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         row_settings=['var_names'])\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0;31m     summary_list = forward_pass(\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mexecuted_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 2, Conv2d: 3, BatchNorm2d: 3, ReLU: 3, Conv2d: 3, BatchNorm2d: 3]"],"ename":"RuntimeError","evalue":"Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 2, Conv2d: 3, BatchNorm2d: 3, ReLU: 3, Conv2d: 3, BatchNorm2d: 3]","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"# stage_02에 입력되기 전 입력 feature map의 size를 절반으로 줄여주는 downsample block 생성. \ndownsample_02 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n            nn.BatchNorm2d(128)    \n)\nstage_02 = nn.Sequential(\n    BasicBlock(in_channels=64, last_channels=128, stride=2, downsample=downsample_02),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None)\n)\n\nsummary(model=stage_02, input_size=(1, 64, 56, 56),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:26:09.017987Z","iopub.execute_input":"2025-01-14T01:26:09.018277Z","iopub.status.idle":"2025-01-14T01:26:09.048016Z","shell.execute_reply.started":"2025-01-14T01:26:09.018251Z","shell.execute_reply":"2025-01-14T01:26:09.047299Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"===================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #\n===================================================================================================================\nSequential (Sequential)                  [1, 64, 56, 56]           [1, 128, 28, 28]          --\n├─BasicBlock (0)                         [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    └─Sequential (conv_block)           [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    └─Conv2d (0)                   [1, 64, 56, 56]           [1, 128, 28, 28]          73,728\n│    │    └─BatchNorm2d (1)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (2)                     [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (3)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (4)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    └─Sequential (downsample)           [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    └─Conv2d (0)                   [1, 64, 56, 56]           [1, 128, 28, 28]          8,192\n│    │    └─BatchNorm2d (1)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n├─BasicBlock (1)                         [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─Sequential (conv_block)           [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (0)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (1)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (2)                     [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (3)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (4)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n├─BasicBlock (2)                         [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─Sequential (conv_block)           [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (0)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (1)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (2)                     [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (3)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (4)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n├─BasicBlock (3)                         [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─Sequential (conv_block)           [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (0)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (1)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (2)                     [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (3)                   [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (4)              [1, 128, 28, 28]          [1, 128, 28, 28]          256\n===================================================================================================================\nTotal params: 1,116,416\nTrainable params: 1,116,416\nNon-trainable params: 0\nTotal mult-adds (M): 873.47\n===================================================================================================================\nInput size (MB): 0.80\nForward/backward pass size (MB): 14.45\nParams size (MB): 4.47\nEstimated Total Size (MB): 19.72\n==================================================================================================================="},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"#### stage별로 Sequential로 Basic Block을 연결하는 코드는 반복적인 부분이 많이 필요","metadata":{}},{"cell_type":"code","source":"stage_01 = nn.Sequential(\n    BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None),\n    BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None),\n    BasicBlock(in_channels=64, last_channels=64, stride=1, downsample=None)\n)\n\ndownsample_02 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n            nn.BatchNorm2d(128)    \n)\nstage_02 = nn.Sequential(\n    BasicBlock(in_channels=64, last_channels=128, stride=2, downsample=downsample_02),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None),\n    BasicBlock(in_channels=128, last_channels=128, stride=1, downsample=None)\n)\n### stage 3은 BasicBlock 6개, \n'''\ndownsample_03 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False),\n            nn.BatchNorm2d(256)    \n)\nstage_03 = nn.Sequential(\n    BasicBlock(in_channels=128, middle_channels=256, last_channels=64, stride=2, downsample=downsample_03),\n    BasicBlock(in_channels=256, middle_channels=256, last_channels=128, stride=1, downsample=None),\n    .....\n    BasicBlock(in_channels=256, middle_channels=256, last_channels=128, stride=1, downsample=None)\n)\n### stage 4는 BasicBlock 3개\n.....\n'''\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### BasicBlock들을 서로 연결하여 Stage를 만들어주는 함수 생성","metadata":{}},{"cell_type":"code","source":"def make_basic_stage(in_channels, last_channels, stride, blocks):\n    # 모든 BasicBlock들을 담을 List\n    layers = []\n    downsample = None\n    # 함수의 인자로 stride가 1이 아닌 2가 들어올 경우 downsample 생성. \n    if stride != 1:\n        downsample = nn.Sequential(\n            nn.Conv2d(in_channels=in_channels, out_channels=last_channels,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(num_features=last_channels)\n        )\n    # 각 stage의 첫번째 Block. 함수의 stride 인자가 1 또는 2인지에 따라 생성된 downsample을 BasicBlock의 인자로 입력.\n    layers.append(BasicBlock(in_channels=in_channels, last_channels=last_channels,\n                             stride=stride, downsample=downsample))\n    for _ in range(1, blocks): \n        # 각 stage의 첫번째 Block을 제외하고는 모두 stride=1, downsample=None\n        layers.append(BasicBlock(in_channels=last_channels, last_channels=last_channels,\n                                 stride=1, downsample=None))\n    #layers list에 있는 모든 BasicBlock들을 Sequential로 연결하여 반환 \n    return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:55:00.087907Z","iopub.execute_input":"2025-01-14T01:55:00.088202Z","iopub.status.idle":"2025-01-14T01:55:00.093451Z","shell.execute_reply.started":"2025-01-14T01:55:00.088178Z","shell.execute_reply":"2025-01-14T01:55:00.092598Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"stage_01 = make_basic_stage(in_channels=64, last_channels=64, stride=1, blocks=3)\nprint(stage_01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:55:08.637431Z","iopub.execute_input":"2025-01-14T01:55:08.637754Z","iopub.status.idle":"2025-01-14T01:55:08.646348Z","shell.execute_reply.started":"2025-01-14T01:55:08.637703Z","shell.execute_reply":"2025-01-14T01:55:08.645502Z"}},"outputs":[{"name":"stdout","text":"Sequential(\n  (0): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (1): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (2): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"stage_02 = make_basic_stage(in_channels=64, last_channels=128, stride=2, blocks=4)\nprint(stage_02)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:55:29.085174Z","iopub.execute_input":"2025-01-14T01:55:29.085445Z","iopub.status.idle":"2025-01-14T01:55:29.100648Z","shell.execute_reply.started":"2025-01-14T01:55:29.085422Z","shell.execute_reply":"2025-01-14T01:55:29.099683Z"}},"outputs":[{"name":"stdout","text":"Sequential(\n  (0): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (downsample): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (1): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (2): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (3): BasicBlock(\n    (conv_block): Sequential(\n      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU()\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### Resnet 34 모델 만들기","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, last_channels, stride=1, downsample=None):\n        '''\n        입력 채널수, 중간 채널 수, 최종 채널수\n        stride는 기본 1. stage 별로 feature map의 크기를 줄일 경우 2\n        downsample은 stride가 2일 경우 BasicBlock 입력 전 값도 1x1 conv, stride 2를 적용하여 사이즈를 줄이는 Conv block\n        '''\n        super().__init__()\n        self.conv_block = nn.Sequential(\n            # 첫번째 3x3 Conv. stage별로 Feature Map의 크기를 줄일 시 첫번째 Conv에서 줄임(3x3 kernel에 stride=2로)\n            nn.Conv2d(in_channels, last_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(last_channels),\n            nn.ReLU(),\n            # 두번째 3x3 Conv\n            nn.Conv2d(last_channels, last_channels, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(last_channels),\n        )\n        self.stride = stride\n        self.downsample = downsample\n\n    def forward(self, x):\n        identity = x\n        out = self.conv_block(x)\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        \n        out += identity\n        out = F.relu(out)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T01:58:01.784652Z","iopub.execute_input":"2025-01-14T01:58:01.784998Z","iopub.status.idle":"2025-01-14T01:58:01.791198Z","shell.execute_reply.started":"2025-01-14T01:58:01.784968Z","shell.execute_reply":"2025-01-14T01:58:01.790442Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class ResNet34(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.conv_block_01 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        # 3, 4, 6, 3개의 BasicBlock들로 이루어진 stage들. \n        self.stage_01 = self.make_basic_stage(in_channels=64, last_channels=64, stride=1, blocks=3)\n        self.stage_02 = self.make_basic_stage(in_channels=64, last_channels=128, stride=2, blocks=4)\n        self.stage_03 = self.make_basic_stage(in_channels=128, last_channels=256, stride=2, blocks=6)\n        self.stage_04 = self.make_basic_stage(in_channels=256, last_channels=512, stride=2, blocks=3)\n\n        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size=1)\n        self.fc = nn.Linear(512, num_classes)\n\n    def make_basic_stage(self, in_channels, last_channels, stride, blocks):\n        # 모든 BasicBlock들을 담을 List\n        layers = []\n        downsample = None\n        # 함수의 인자로 stride가 1이 아닌 2가 들어올 경우 downsample 생성. \n        if stride != 1:\n            downsample = nn.Sequential(\n                nn.Conv2d(in_channels=in_channels, out_channels=last_channels, \n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(num_features=last_channels)\n            )\n        # 각 stage의 첫번째 Block. 함수의 stride 인자가 1 또는 2인지에 따라 생성된 downsample을 BasicBlock의 인자로 입력. \n        layers.append(BasicBlock(in_channels=in_channels, last_channels=last_channels,\n                                     stride=stride, downsample=downsample))\n        for _ in range(1, blocks):\n            # 각 stage의 첫번째 Block을 제외하고는 모두 stride=1, downsample=None \n            layers.append(BasicBlock(in_channels=last_channels, last_channels=last_channels, \n                                    stride=1, downsample=None))\n        \n        #layer list에 있는 모든 BasicBlock들을 Sequential로 연결하여 반환 \n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv_block_01(x)\n        x = self.stage_01(x)\n        x = self.stage_02(x)\n        x = self.stage_03(x)\n        x = self.stage_04(x)\n        \n        # GAP 및 최종 Classifier Layer forward\n        x = self.adaptive_pool(x)\n        x = torch.flatten(x, start_dim=1)\n        x = self.fc(x)\n\n        return x\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T02:20:21.455820Z","iopub.execute_input":"2025-01-14T02:20:21.456168Z","iopub.status.idle":"2025-01-14T02:20:21.464412Z","shell.execute_reply.started":"2025-01-14T02:20:21.456139Z","shell.execute_reply":"2025-01-14T02:20:21.463626Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"my_resnet34_model = ResNet34(num_classes=1000)\n\nsummary(model=my_resnet34_model, input_size=(1, 3, 224, 224),\n        col_names=['input_size', 'output_size', 'num_params'],\n        depth=4,\n        row_settings=['var_names'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T02:21:11.789815Z","iopub.execute_input":"2025-01-14T02:21:11.790096Z","iopub.status.idle":"2025-01-14T02:21:11.987259Z","shell.execute_reply.started":"2025-01-14T02:21:11.790074Z","shell.execute_reply":"2025-01-14T02:21:11.986434Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"===================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #\n===================================================================================================================\nResNet34 (ResNet34)                      [1, 3, 224, 224]          [1, 1000]                 --\n├─Sequential (conv_block_01)             [1, 3, 224, 224]          [1, 64, 56, 56]           --\n│    └─Conv2d (0)                        [1, 3, 224, 224]          [1, 64, 112, 112]         9,408\n│    └─BatchNorm2d (1)                   [1, 64, 112, 112]         [1, 64, 112, 112]         128\n│    └─ReLU (2)                          [1, 64, 112, 112]         [1, 64, 112, 112]         --\n│    └─MaxPool2d (3)                     [1, 64, 112, 112]         [1, 64, 56, 56]           --\n├─Sequential (stage_01)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (0)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Sequential (conv_block)      [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    │    └─Conv2d (0)              [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    │    └─BatchNorm2d (1)         [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    │    └─ReLU (2)                [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    │    └─Conv2d (3)              [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    │    └─BatchNorm2d (4)         [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    └─BasicBlock (1)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Sequential (conv_block)      [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    │    └─Conv2d (0)              [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    │    └─BatchNorm2d (1)         [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    │    └─ReLU (2)                [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    │    └─Conv2d (3)              [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    │    └─BatchNorm2d (4)         [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    └─BasicBlock (2)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Sequential (conv_block)      [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    │    └─Conv2d (0)              [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    │    └─BatchNorm2d (1)         [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    │    └─ReLU (2)                [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    │    └─Conv2d (3)              [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    │    └─BatchNorm2d (4)         [1, 64, 56, 56]           [1, 64, 56, 56]           128\n├─Sequential (stage_02)                  [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    └─BasicBlock (0)                    [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    └─Sequential (conv_block)      [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (0)              [1, 64, 56, 56]           [1, 128, 28, 28]          73,728\n│    │    │    └─BatchNorm2d (1)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    │    └─ReLU (2)                [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (3)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (4)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─Sequential (downsample)      [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (0)              [1, 64, 56, 56]           [1, 128, 28, 28]          8,192\n│    │    │    └─BatchNorm2d (1)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    └─BasicBlock (1)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Sequential (conv_block)      [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (0)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (1)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    │    └─ReLU (2)                [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (3)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (4)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    └─BasicBlock (2)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Sequential (conv_block)      [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (0)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (1)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    │    └─ReLU (2)                [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (3)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (4)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    └─BasicBlock (3)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Sequential (conv_block)      [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (0)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (1)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    │    └─ReLU (2)                [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    │    └─Conv2d (3)              [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    │    └─BatchNorm2d (4)         [1, 128, 28, 28]          [1, 128, 28, 28]          256\n├─Sequential (stage_03)                  [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    └─BasicBlock (0)                    [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    │    └─Sequential (conv_block)      [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 128, 28, 28]          [1, 256, 14, 14]          294,912\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    │    └─ReLU (2)                [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (3)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (4)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─Sequential (downsample)      [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 128, 28, 28]          [1, 256, 14, 14]          32,768\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    └─BasicBlock (1)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Sequential (conv_block)      [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    │    └─ReLU (2)                [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (3)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (4)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    └─BasicBlock (2)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Sequential (conv_block)      [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    │    └─ReLU (2)                [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (3)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (4)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    └─BasicBlock (3)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Sequential (conv_block)      [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    │    └─ReLU (2)                [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (3)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (4)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    └─BasicBlock (4)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Sequential (conv_block)      [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    │    └─ReLU (2)                [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (3)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (4)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    └─BasicBlock (5)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Sequential (conv_block)      [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (1)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    │    └─ReLU (2)                [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    │    └─Conv2d (3)              [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    │    └─BatchNorm2d (4)         [1, 256, 14, 14]          [1, 256, 14, 14]          512\n├─Sequential (stage_04)                  [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    └─BasicBlock (0)                    [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    │    └─Sequential (conv_block)      [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 512, 7, 7]            1,179,648\n│    │    │    └─BatchNorm2d (1)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    │    └─ReLU (2)                [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (3)              [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    │    └─BatchNorm2d (4)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─Sequential (downsample)      [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (0)              [1, 256, 14, 14]          [1, 512, 7, 7]            131,072\n│    │    │    └─BatchNorm2d (1)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    └─BasicBlock (1)                    [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Sequential (conv_block)      [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (0)              [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    │    └─BatchNorm2d (1)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    │    └─ReLU (2)                [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (3)              [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    │    └─BatchNorm2d (4)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    └─BasicBlock (2)                    [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Sequential (conv_block)      [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (0)              [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    │    └─BatchNorm2d (1)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    │    └─ReLU (2)                [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    │    └─Conv2d (3)              [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    │    └─BatchNorm2d (4)         [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n├─AdaptiveAvgPool2d (adaptive_pool)      [1, 512, 7, 7]            [1, 512, 1, 1]            --\n├─Linear (fc)                            [1, 512]                  [1, 1000]                 513,000\n===================================================================================================================\nTotal params: 21,797,672\nTrainable params: 21,797,672\nNon-trainable params: 0\nTotal mult-adds (G): 3.66\n===================================================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 59.82\nParams size (MB): 87.19\nEstimated Total Size (MB): 147.61\n==================================================================================================================="},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"torch_resnet34_model = models.resnet34(weights='DEFAULT')\nsummary(model=torch_resnet34_model, input_size=(1, 3, 224, 224),\n        col_names=['input_size', 'output_size', 'num_params'], \n        row_settings=['var_names'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T02:21:39.184057Z","iopub.execute_input":"2025-01-14T02:21:39.184351Z","iopub.status.idle":"2025-01-14T02:21:39.594035Z","shell.execute_reply.started":"2025-01-14T02:21:39.184325Z","shell.execute_reply":"2025-01-14T02:21:39.593125Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"===================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #\n===================================================================================================================\nResNet (ResNet)                          [1, 3, 224, 224]          [1, 1000]                 --\n├─Conv2d (conv1)                         [1, 3, 224, 224]          [1, 64, 112, 112]         9,408\n├─BatchNorm2d (bn1)                      [1, 64, 112, 112]         [1, 64, 112, 112]         128\n├─ReLU (relu)                            [1, 64, 112, 112]         [1, 64, 112, 112]         --\n├─MaxPool2d (maxpool)                    [1, 64, 112, 112]         [1, 64, 56, 56]           --\n├─Sequential (layer1)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (0)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (1)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    └─BasicBlock (2)                    [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n│    │    └─Conv2d (conv2)               [1, 64, 56, 56]           [1, 64, 56, 56]           36,864\n│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]           [1, 64, 56, 56]           128\n│    │    └─ReLU (relu)                  [1, 64, 56, 56]           [1, 64, 56, 56]           --\n├─Sequential (layer2)                    [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    └─BasicBlock (0)                    [1, 64, 56, 56]           [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 64, 56, 56]           [1, 128, 28, 28]          73,728\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─Sequential (downsample)      [1, 64, 56, 56]           [1, 128, 28, 28]          8,448\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─BasicBlock (1)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─BasicBlock (2)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    └─BasicBlock (3)                    [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n│    │    └─Conv2d (conv2)               [1, 128, 28, 28]          [1, 128, 28, 28]          147,456\n│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]          [1, 128, 28, 28]          256\n│    │    └─ReLU (relu)                  [1, 128, 28, 28]          [1, 128, 28, 28]          --\n├─Sequential (layer3)                    [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    └─BasicBlock (0)                    [1, 128, 28, 28]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 128, 28, 28]          [1, 256, 14, 14]          294,912\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─Sequential (downsample)      [1, 128, 28, 28]          [1, 256, 14, 14]          33,280\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (1)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (2)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (3)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (4)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    └─BasicBlock (5)                    [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n│    │    └─Conv2d (conv2)               [1, 256, 14, 14]          [1, 256, 14, 14]          589,824\n│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]          [1, 256, 14, 14]          512\n│    │    └─ReLU (relu)                  [1, 256, 14, 14]          [1, 256, 14, 14]          --\n├─Sequential (layer4)                    [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    └─BasicBlock (0)                    [1, 256, 14, 14]          [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv1)               [1, 256, 14, 14]          [1, 512, 7, 7]            1,179,648\n│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─Sequential (downsample)      [1, 256, 14, 14]          [1, 512, 7, 7]            132,096\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    └─BasicBlock (1)                    [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    └─BasicBlock (2)                    [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv1)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n│    │    └─Conv2d (conv2)               [1, 512, 7, 7]            [1, 512, 7, 7]            2,359,296\n│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]            [1, 512, 7, 7]            1,024\n│    │    └─ReLU (relu)                  [1, 512, 7, 7]            [1, 512, 7, 7]            --\n├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]            [1, 512, 1, 1]            --\n├─Linear (fc)                            [1, 512]                  [1, 1000]                 513,000\n===================================================================================================================\nTotal params: 21,797,672\nTrainable params: 21,797,672\nNon-trainable params: 0\nTotal mult-adds (G): 3.66\n===================================================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 59.82\nParams size (MB): 87.19\nEstimated Total Size (MB): 147.61\n==================================================================================================================="},"metadata":{}}],"execution_count":33}]}